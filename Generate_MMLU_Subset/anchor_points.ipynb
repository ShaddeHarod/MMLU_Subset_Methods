{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aeb0a714-9d15-41bc-ac06-ce5a1e448b1d",
   "metadata": {},
   "source": [
    "# Finding and using anchor points\n",
    "\n",
    "In this notebook, we show how to find anchor points based on your training set and how to use them to estimate the performance of new models in the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7008d96d-1ee5-44cf-91cb-293fb3e048bf",
   "metadata": {},
   "source": [
    "## Preparing data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b85d9b93-5059-416c-8a53-e3b4cc24a904",
   "metadata": {},
   "source": [
    "Loading packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7892164d-f5bb-4cef-9f4f-685a9af85679",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import json\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "from irt import *\n",
    "from utils import *\n",
    "random_state = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ebb8ce2-1851-4131-8d35-36214be71085",
   "metadata": {},
   "source": [
    "The leaderboard dataset we will use is composed by six scenarios (sub-datasets):\n",
    "1. TruthfulQA\n",
    "1. GSM8K\n",
    "1. Winogrande\n",
    "1. ARC\n",
    "1. HellaSwag\n",
    "1. MMLU\n",
    "\n",
    "MMLU is further divided into sub-scenarios (e.g., abstract algebra, anatomy, etc). Let's check scenarios and sub-scenarios:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26499fc1-2bda-44b2-9131-e78d16f7f77d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'harness_truthfulqa_mc_0': ['harness_truthfulqa_mc_0'],\n",
       " 'gsm8k': ['harness_gsm8k_5'],\n",
       " 'winogrande': ['harness_winogrande_5'],\n",
       " 'arc': ['harness_arc_challenge_25'],\n",
       " 'hellaswag': ['harness_hellaswag_10'],\n",
       " 'mmlu': ['harness_hendrycksTest_abstract_algebra_5',\n",
       "  'harness_hendrycksTest_anatomy_5',\n",
       "  'harness_hendrycksTest_astronomy_5',\n",
       "  'harness_hendrycksTest_business_ethics_5',\n",
       "  'harness_hendrycksTest_clinical_knowledge_5',\n",
       "  'harness_hendrycksTest_college_biology_5',\n",
       "  'harness_hendrycksTest_college_chemistry_5',\n",
       "  'harness_hendrycksTest_college_computer_science_5',\n",
       "  'harness_hendrycksTest_college_mathematics_5',\n",
       "  'harness_hendrycksTest_college_medicine_5',\n",
       "  'harness_hendrycksTest_college_physics_5',\n",
       "  'harness_hendrycksTest_computer_security_5',\n",
       "  'harness_hendrycksTest_conceptual_physics_5',\n",
       "  'harness_hendrycksTest_econometrics_5',\n",
       "  'harness_hendrycksTest_electrical_engineering_5',\n",
       "  'harness_hendrycksTest_elementary_mathematics_5',\n",
       "  'harness_hendrycksTest_formal_logic_5',\n",
       "  'harness_hendrycksTest_global_facts_5',\n",
       "  'harness_hendrycksTest_high_school_biology_5',\n",
       "  'harness_hendrycksTest_high_school_chemistry_5',\n",
       "  'harness_hendrycksTest_high_school_computer_science_5',\n",
       "  'harness_hendrycksTest_high_school_european_history_5',\n",
       "  'harness_hendrycksTest_high_school_geography_5',\n",
       "  'harness_hendrycksTest_high_school_government_and_politics_5',\n",
       "  'harness_hendrycksTest_high_school_macroeconomics_5',\n",
       "  'harness_hendrycksTest_high_school_mathematics_5',\n",
       "  'harness_hendrycksTest_high_school_microeconomics_5',\n",
       "  'harness_hendrycksTest_high_school_physics_5',\n",
       "  'harness_hendrycksTest_high_school_psychology_5',\n",
       "  'harness_hendrycksTest_high_school_statistics_5',\n",
       "  'harness_hendrycksTest_high_school_us_history_5',\n",
       "  'harness_hendrycksTest_high_school_world_history_5',\n",
       "  'harness_hendrycksTest_human_aging_5',\n",
       "  'harness_hendrycksTest_human_sexuality_5',\n",
       "  'harness_hendrycksTest_international_law_5',\n",
       "  'harness_hendrycksTest_jurisprudence_5',\n",
       "  'harness_hendrycksTest_logical_fallacies_5',\n",
       "  'harness_hendrycksTest_machine_learning_5',\n",
       "  'harness_hendrycksTest_management_5',\n",
       "  'harness_hendrycksTest_marketing_5',\n",
       "  'harness_hendrycksTest_medical_genetics_5',\n",
       "  'harness_hendrycksTest_miscellaneous_5',\n",
       "  'harness_hendrycksTest_moral_disputes_5',\n",
       "  'harness_hendrycksTest_moral_scenarios_5',\n",
       "  'harness_hendrycksTest_nutrition_5',\n",
       "  'harness_hendrycksTest_philosophy_5',\n",
       "  'harness_hendrycksTest_prehistory_5',\n",
       "  'harness_hendrycksTest_professional_accounting_5',\n",
       "  'harness_hendrycksTest_professional_law_5',\n",
       "  'harness_hendrycksTest_professional_medicine_5',\n",
       "  'harness_hendrycksTest_professional_psychology_5',\n",
       "  'harness_hendrycksTest_public_relations_5',\n",
       "  'harness_hendrycksTest_security_studies_5',\n",
       "  'harness_hendrycksTest_sociology_5',\n",
       "  'harness_hendrycksTest_us_foreign_policy_5',\n",
       "  'harness_hendrycksTest_virology_5',\n",
       "  'harness_hendrycksTest_world_religions_5']}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scenarios"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b34e5620-bd45-4985-b390-a154843b4d6c",
   "metadata": {},
   "source": [
    "Loading leaderboard data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ca68f5c-49de-4f75-92e5-de639059cec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/lb.pickle', 'rb') as handle:\n",
    "    data = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87d8135b-e9ec-468a-85a7-3cd3fc3d31fe",
   "metadata": {},
   "source": [
    "Below, we will process the data so all correctness scores (for all scenarios) are stored in $Y$. The dictionaries `scenarios_position` and `subscenarios_position` give the position of scenarios/subscenarios correctness scores in $Y$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee09c25b-2dc4-4403-a972-9fb05cfe917b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(395, 28659)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scenarios_position, subscenarios_position = prepare_data(scenarios, data)\n",
    "Y = create_responses(scenarios, data)\n",
    "Y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e002485a-1e82-409b-aaf2-ddb6a82bc315",
   "metadata": {},
   "source": [
    "For example, below you can see the scores for MMLU:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c4dd9649-ba75-49c0-92fe-b00d2afc252e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0., 0., 1., ..., 1., 1., 0.],\n",
       "        [0., 0., 1., ..., 1., 1., 0.],\n",
       "        [0., 0., 1., ..., 1., 1., 0.],\n",
       "        ...,\n",
       "        [0., 0., 1., ..., 1., 1., 0.],\n",
       "        [0., 0., 1., ..., 1., 1., 0.],\n",
       "        [1., 0., 1., ..., 1., 1., 0.]]),\n",
       " (395, 14042))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y[:,scenarios_position['mmlu']], Y[:,scenarios_position['mmlu']].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "662681a7-10b0-4ddc-a692-52d278499539",
   "metadata": {},
   "source": [
    "For scenarios that have multiple subscenarios, it is usually the case that we want to give equal importance to individual subscenarios when computing the aggregated performance in that scenario. This is equivalent to using a weighted average when computing the aggregated performance. We will create `balance_weights`, a vector of weights to help us compute those weighted averages. These weights will be different than one only for MMLU, which is the only scenario with multiple subscenarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1f40fc53-b11e-41cc-adc2-7abff1a2b368",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 28659 包含包括mmlu所有场景的子集，和其他的数据集的subscenario\n",
    "balance_weights = np.ones(Y.shape[1])\n",
    "# N为MMLU的问题总数\n",
    "N = len(scenarios_position['mmlu'])\n",
    "# n_sub为mmlu科目数量\n",
    "n_sub = len(scenarios['mmlu'])\n",
    "# sub为科目\n",
    "for sub in scenarios['mmlu']:\n",
    "    # n_i为对应subject题目数量\n",
    "    n_i = len(subscenarios_position['mmlu'][sub])\n",
    "    # idx = subscenario_position['mmlu'][sub],是mmlu子集在所有subscenrio中的位置\n",
    "    # n_sub * n_i 为对应subject的问题数量，乘上mmlu科目数量（57）。balance_weights中有大于1有小于1的，大于1说明科目数量小，给予更高的weight\n",
    "    balance_weights[subscenarios_position['mmlu'][sub]] = N/(n_sub*n_i)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "971d42b7-c6ac-4695-a5f0-3087c091d16d",
   "metadata": {},
   "source": [
    "We can see below that first averaging within subscenarios and then computing a simple average is equivalent to using a weighted average from the beginning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b7b51b6f-5ce5-46bf-ba44-836386db05f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.322333605307685e-14"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# accs1 先计算每个模型同一个科目的总准确率，再把每个模型的所有科目的准确率汇总等权，计算每个模型的准确率，形成(395, )的准确率\n",
    "accs1 = np.mean([Y[:,subscenarios_position['mmlu'][sub]].mean(axis=1) for sub in scenarios['mmlu']], axis=0)\n",
    "# balance_weights*Y，每行大模型的0/1正确率都会乘上对应的weight。scenarios_position['mmlu']取14042个问题对应的index。mean后为每个模型的总准确率，形状为（395,）\n",
    "accs2 = (balance_weights*Y)[:,scenarios_position['mmlu']].mean(axis=1)\n",
    "# 两者结果一致\n",
    "np.abs(accs1 - accs2).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d106b620-7fe0-49bb-a8ac-3a946c15f751",
   "metadata": {},
   "source": [
    "## Getting and using anchor points"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a528f89a-64bb-497e-b993-9181996d75d1",
   "metadata": {},
   "source": [
    "The variable `clustering` specified how the clusting is run. If `clustering=\"correct.\"`, then correctness is used. On the other hand, if `clustering=\"irt\"`, then the IRT embeddings for examples are used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3b3fff9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "clustering = 'correct.' # 'correct.' or 'irt'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e5edf1d-21b3-46f9-9034-479ebe89314d",
   "metadata": {},
   "source": [
    "Computing anchor points and their weights for each scenario:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "313c85b8-838d-416c-ac7d-e40725e08853",
   "metadata": {},
   "outputs": [],
   "source": [
    "anchor_points = {}\n",
    "anchor_weights = {}\n",
    "\n",
    "for scenario in scenarios.keys():\n",
    "    # X 若为correct cluster，则每行为mmlu题目，每列为模型回答的0/1的答案，列数为模型数\n",
    "    # X 若为irt cluster，则每行为mmlu题目，每列为题目区分度A和难度B，列数为2\n",
    "    if clustering=='correct.':\n",
    "        X = Y_train[:,scenarios_position[scenario]].T\n",
    "    elif clustering=='irt':\n",
    "        #这行代码会从预先训练好的 IRT 模型中加载每个题目的两个核心参数：\n",
    "        # `A` (Discrimination/区分度): 表示一个题目在区分高能力和低能力模型上的效果有多好。A 值越高，区分度越好。\n",
    "        # `B` (Difficulty/难度): 表示一个题目的难度值。B 值越高，题目越难。\n",
    "        A, B, _ = load_irt_parameters('data/irt_model/')\n",
    "        # 首先，它将所有题目的 A 和 B 参数合并成一个矩阵。转置（.T）后，这个矩阵的每一行代表一道题目，而两列分别是这道题的区分度（A）和难度（B）。\n",
    "        X = np.vstack((A.squeeze(), B.squeeze().reshape((1,-1)))).T\n",
    "        # 然后，它从这个总矩阵中筛选出当前 scenario (例如 'mmlu') 所对应的那些题目。\n",
    "        X = X[scenarios_position[scenario]]\n",
    "    else:\n",
    "        raise NotImplementedError \n",
    "        \n",
    "    #Normalizing balance_weights, so their sum is one within each scenario\n",
    "    norm_balance_weights = balance_weights[scenarios_position[scenario]]\n",
    "    norm_balance_weights /= norm_balance_weights.sum()\n",
    "\n",
    "    # Fitting the KMeans model\n",
    "    # * kmeans.labels_:\n",
    "    #   * 内容: 一个一维数组，长度与 X 的行数（即题目数量）相同。数组中的第 i 个值，就是第 i 道题目被分配到的簇的编号（从 0\n",
    "    #     到 99）。\n",
    "    #   * 作用: 这是最直接的聚类结果，告诉我们每道题属于哪个簇。\n",
    "\n",
    "    #* kmeans.cluster_centers_:\n",
    "    #   * 内容: 一个形状为 (100, 特征数量) 的二维数组。每一行代表一个簇的中心点（质心）在特征空间中的坐标。\n",
    "    #   * 作用: 代表了 100 个簇的“平均”特征。后续代码会用它来寻找离每个中心点最近的真实题目，作为“锚点”。\n",
    "\n",
    "    #* kmeans.inertia_:\n",
    "    #   * 内容: 一个浮点数，表示所有样本点到其所属簇中心的距离平方和。\n",
    "    #   * 作用: 它是衡量聚类效果的一个指标，值越小通常表示聚类效果越好（簇内更紧密）。\n",
    "    kmeans = KMeans(n_clusters=number_item, n_init=\"auto\", random_state=random_state)\n",
    "    kmeans.fit(X, sample_weight=norm_balance_weights)\n",
    "\n",
    "    # Calculating anchor points\n",
    "    # 对于 KMeans 算法找到的 100 个簇，分别计算出离每个簇的中心点最近的那道真实题目，并将这 100道真实题目的索引作为该场景下的“锚点”保存下来。\n",
    "    # 这些“锚点”就是对整个题库进行浓缩和降维后得到的、最具代表性的题目样本。\n",
    "    anchor_points[scenario] = pairwise_distances(kmeans.cluster_centers_, X, metric='euclidean').argmin(axis=1)\n",
    "\n",
    "    # Calculating anchor weights\n",
    "    # 对number_item个簇，计算每个簇的权重，权重为该簇内所有题目权重的和\n",
    "    # kmeans.labels_ == c:\n",
    "    #   * 这是一个布尔判断。对于当前的簇编号 c，它会生成一个布尔类型的“掩码” (mask) 数组。\n",
    "    #   * 例如，当 c=5 时，这个掩码数组中，所有属于第 5 簇的题目的位置为 True，其他都为 False。\n",
    "    # norm_balance_weights[...]:\n",
    "    #   * norm_balance_weights 是一个数组，包含了每一道题目的归一化权重。\n",
    "    #   * norm_balance_weights[kmeans.labels_==c] 这个操作利用上面的布尔掩码，从 norm_balance_weights 中只挑选出那些属于簇`c` 的题目的权重。\n",
    "    anchor_weights[scenario] = np.array([np.sum(norm_balance_weights[kmeans.labels_==c]) for c in range(number_item)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c071b44-1410-4cb8-9d20-2f5a3ed9c5c9",
   "metadata": {},
   "source": [
    "Saving"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "651edaf8-af28-4e6f-92d6-192477c0aa44",
   "metadata": {},
   "source": [
    "Checking results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "11008304-b6db-4b55-863d-c9968a0b76ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "anchor = {'anchor_points':anchor_points,\n",
    "          'anchor_weights':anchor_weights}\n",
    "\n",
    "with open('data/anchor.pickle', 'wb') as handle:\n",
    "    pickle.dump(anchor, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5a468b8f-950b-41c5-b009-e9b3d913b0c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1147,   666,  8256,   504, 13241,  1503, 13572,  1894,  9286,\n",
       "         265,  1961,  7870,  9004,  8691,  3683,  8468,  3141,  8504,\n",
       "        4458,   637,   557,  8168, 12351,  2594,  4963,  7707,  6886,\n",
       "        6546,  7707,  1109,  2659, 11216, 13545,  7286,  9531,    68,\n",
       "        8214,  3575,  1868,  7870,  7342,  3629, 13631,  2498,  5221,\n",
       "        7024,   923,  2651,  5962,  1488,   668,  6412, 14026,  2870,\n",
       "        5366,   418,  2316,  7225, 13296,  7707, 13779,  3219, 14017,\n",
       "       12968,   959,  5961, 10509,  8168,    55,  8012,  1959, 10379,\n",
       "        1025, 13978, 10813,  1349, 11209,  2153,   858,  6887,  3254,\n",
       "        2313,  1980,   265,    25,  6167,  7342,  1124,  4784,  8894,\n",
       "        4368,  6539,  4880,  4151, 11553,  7304, 11931,     0,  1018,\n",
       "        1786], dtype=int64)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anchor_points['mmlu']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e6955cb1-de2d-4346-a12e-4356e464c2c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.0042764 , 0.02905955, 0.06135599, 0.00945872, 0.00536487,\n",
       "       0.03758534, 0.00856022, 0.00549396, 0.00403803, 0.00997437,\n",
       "       0.00730435, 0.00539472, 0.00272371, 0.00394002, 0.01031464,\n",
       "       0.00679635, 0.00634383, 0.00358692, 0.00296083, 0.01802555,\n",
       "       0.00594566, 0.04414731, 0.01086474, 0.00268234, 0.01827593,\n",
       "       0.00933639, 0.00135921, 0.01064351, 0.00888152, 0.00501712,\n",
       "       0.00101003, 0.0096813 , 0.00513194, 0.00606622, 0.00389487,\n",
       "       0.01298388, 0.00380664, 0.009867  , 0.00183478, 0.01108704,\n",
       "       0.00823578, 0.00545061, 0.00292699, 0.00850653, 0.0062363 ,\n",
       "       0.00187063, 0.00476257, 0.00200589, 0.01161997, 0.00428859,\n",
       "       0.01155459, 0.01342028, 0.00850961, 0.00618165, 0.00663006,\n",
       "       0.06445207, 0.00599398, 0.01817672, 0.00697267, 0.01280029,\n",
       "       0.01402079, 0.00628686, 0.02230109, 0.00489392, 0.00147227,\n",
       "       0.01523384, 0.01902777, 0.01244332, 0.00585419, 0.01393512,\n",
       "       0.0107454 , 0.00489883, 0.00580522, 0.00561106, 0.01013878,\n",
       "       0.0026508 , 0.00882797, 0.00618554, 0.00897182, 0.00449065,\n",
       "       0.0410602 , 0.00631021, 0.00682846, 0.00845149, 0.00453353,\n",
       "       0.0122241 , 0.00472756, 0.00384274, 0.0142466 , 0.00309615,\n",
       "       0.0075293 , 0.01516813, 0.00288972, 0.00524834, 0.02243518,\n",
       "       0.00589278, 0.00985355, 0.00172249, 0.00079017, 0.00368249])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anchor_weights['mmlu']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9ac7f2a-9288-4ef5-aa57-7280523cfd4c",
   "metadata": {},
   "source": [
    "Using anchor points to estimate performance in the test set and reporting the average prediction error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4a79301f-1140-474e-bd41-832f9c6d0332",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scenario: harness_truthfulqa_mc_0, avg. error: 0.014\n",
      "scenario: gsm8k, avg. error: 0.037\n",
      "scenario: winogrande, avg. error: 0.021\n",
      "scenario: arc, avg. error: 0.026\n",
      "scenario: hellaswag, avg. error: 0.013\n",
      "scenario: mmlu, avg. error: 0.016\n"
     ]
    }
   ],
   "source": [
    "# Y：（模型数，题目数），每个值为0/1\n",
    "for scenario in scenarios.keys():\n",
    "    # Y_test 形状 （100，题目数量），0/1值\n",
    "    # [:,scenarios_position[scenario]] 第一次筛选，100个模型，和所有对应scenario的题目，使变量变为(100,14042)\n",
    "    # [:,anchor_points[scenario]] 第二次筛选，100个模型，和所有对应scenario的题目中的锚点题目，使变量变为（100，100）\n",
    "    Y_anchor = Y_test[:,scenarios_position[scenario]][:,anchor_points[scenario]]\n",
    "    # `Y_hat`: 通过模型在100个代表性题目上的表现，乘以这些题目的重要性权重，最终估算出每个模型的总成绩。\n",
    "    Y_hat = (Y_anchor*anchor_weights[scenario]).sum(axis=1)\n",
    "    Y_true = (balance_weights*Y_test)[:,scenarios_position[scenario]].mean(axis=1)\n",
    "\n",
    "    print(f\"scenario: {scenario}, avg. error: {np.abs(Y_hat-Y_true).mean():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "601e3a2b",
   "metadata": {},
   "source": [
    "## 生成中文 MMLU 的两个相似子集（各 300 题）\n",
    "\n",
    "- 只使用英文侧的题目表现信号（此处采用英文侧模型在题目上的平均正确率作为难度 proxy），\n",
    "- 排除 subjects：`high_school_us_history`, `security_studies`, `high_school_government_and_politics`, `jurisprudence`, `business_ethics`, `us_foreign_policy`, `global_facts`，`moral_scenarios`, `professional_law`,\n",
    " `moral_disputes` 。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf0b1b25",
   "metadata": {},
   "source": [
    "## 三种方法生成MMLU的300题子集\n",
    "\n",
    "本节将实现三种不同的方法来创建MMLU的300题子集，并对它们的表现进行综合评估：\n",
    "\n",
    "1. **方法一：难度分位桶法（基准方法）** - 基于题目难度分位数进行分桶抽样\n",
    "2. **方法二：IRT聚类法** - 基于IRT参数（难度和区分度）进行K-Means聚类\n",
    "3. **方法三：题目正误矩阵聚类法** - 基于模型作答矩阵进行K-Means聚类\n",
    "\n",
    "每种方法将生成两个子集（各300题），确保两个子集在特征分布上高度匹配且无重叠。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a427f94f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "总MMLU题目数: 14042\n",
      "排除指定科目后的题目数: 10217\n",
      "目标子集大小: 300\n",
      "有效MMLU数据形状: (395, 10217)\n"
     ]
    }
   ],
   "source": [
    "# 设置必要的变量和参数\n",
    "np.random.seed(random_state)\n",
    "\n",
    "# 定义子集大小\n",
    "SUBSET_SIZE = 300\n",
    "\n",
    "# 获取MMLU数据\n",
    "Y_mmlu = Y[:, scenarios_position['mmlu']]  # 形状: (395个模型, 14042个MMLU题目)\n",
    "item_acc = Y_mmlu.mean(axis=0)  # 每题的平均正确率（作为难度proxy）\n",
    "\n",
    "# 读取中文题库以获取题目索引映射\n",
    "df_cn = pd.read_csv('mmlu_ZH-CN.csv')\n",
    "assert df_cn.shape[0] == item_acc.shape[0], '中文题库行数与英文MMLU题数不一致'\n",
    "\n",
    "# 排除指定科目\n",
    "excluded_subjects = {\n",
    "    'high_school_us_history', 'security_studies', 'high_school_government_and_politics',\n",
    "    'jurisprudence', 'business_ethics', 'us_foreign_policy', 'global_facts', 'moral_scenarios',\n",
    "    'professional_law', 'moral_disputes'\n",
    "}\n",
    "mask_keep = ~df_cn['Subject'].isin(excluded_subjects)\n",
    "valid_indices = df_cn[mask_keep].index.values  # 有效题目在原始数据中的索引\n",
    "\n",
    "print(f\"总MMLU题目数: {len(item_acc)}\")\n",
    "print(f\"排除指定科目后的题目数: {len(valid_indices)}\")\n",
    "print(f\"目标子集大小: {SUBSET_SIZE}\")\n",
    "\n",
    "# 为了方便后续处理，创建有效题目的映射\n",
    "Y_mmlu_valid = Y_mmlu[:, valid_indices]  # 只包含有效题目的响应矩阵\n",
    "item_acc_valid = item_acc[valid_indices]  # 只包含有效题目的难度指标\n",
    "\n",
    "print(f\"有效MMLU数据形状: {Y_mmlu_valid.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eea4068d",
   "metadata": {},
   "source": [
    "### 方法一：难度分位桶法（基准方法）\n",
    "\n",
    "使用题目的平均正确率作为难度指标，进行分位数分桶，然后在每个桶内按比例抽样生成两个不重叠的子集。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "57ca7a27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "方法一：难度分位桶法 - 完成\n",
      "subset1_bucket大小: 300\n",
      "subset2_bucket大小: 300\n",
      "重叠题目数: 0\n",
      "subset1_bucket难度范围: 0.005 - 1.000\n",
      "subset2_bucket难度范围: 0.010 - 0.997\n",
      "subset1_bucket平均难度: 0.600\n",
      "subset2_bucket平均难度: 0.594\n",
      "方法一中包含的排除科目: subset1_bucket: [], subset2_bucket: []\n"
     ]
    }
   ],
   "source": [
    "def create_difficulty_bucket_subsets(item_difficulties, valid_indices, subset_size, num_buckets=5, random_state=42):\n",
    "    \"\"\"\n",
    "    基于难度分位桶法创建两个不重叠的子集\n",
    "    \n",
    "    参数:\n",
    "    - item_difficulties: 题目难度指标（越低越难）\n",
    "    - valid_indices: 有效题目在原始数据中的索引\n",
    "    - subset_size: 每个子集的大小\n",
    "    - num_buckets: 分桶数量\n",
    "    - random_state: 随机种子\n",
    "    \n",
    "    返回:\n",
    "    - subset1_indices, subset2_indices: 两个子集在valid_indices中的索引\n",
    "    \"\"\"\n",
    "    rng = np.random.RandomState(random_state)\n",
    "    \n",
    "    # 将难度分为分位桶\n",
    "    bucket_labels = pd.qcut(item_difficulties, q=num_buckets, labels=False, duplicates='drop')\n",
    "    \n",
    "    # 处理可能的桶数不足问题\n",
    "    if pd.isna(bucket_labels).any():\n",
    "        ranks = pd.Series(item_difficulties).rank(method='average') / len(item_difficulties)\n",
    "        bucket_labels = np.minimum((ranks * num_buckets).astype(int), num_buckets - 1)\n",
    "    \n",
    "    # 计算每个桶应该抽取的题目数量（按比例）\n",
    "    bucket_counts = pd.Series(bucket_labels).value_counts().sort_index()\n",
    "    bucket_props = bucket_counts / bucket_counts.sum()\n",
    "    target_counts_float = bucket_props * subset_size\n",
    "    target_counts = np.floor(target_counts_float).astype(int)\n",
    "    \n",
    "    # 分配剩余的题目到比例最大的桶\n",
    "    remainder = subset_size - target_counts.sum()\n",
    "    if remainder > 0:\n",
    "        remainder_probs = target_counts_float - target_counts\n",
    "        remainder_buckets = remainder_probs.nlargest(remainder).index\n",
    "        target_counts[remainder_buckets] += 1\n",
    "    \n",
    "    subset1_indices = []\n",
    "    subset2_indices = []\n",
    "    \n",
    "    # 在每个桶内抽样\n",
    "    for bucket_id in sorted(bucket_counts.index):\n",
    "        bucket_mask = bucket_labels == bucket_id\n",
    "        bucket_items = np.where(bucket_mask)[0]\n",
    "        target_count = target_counts[bucket_id]\n",
    "        \n",
    "        if target_count > 0 and len(bucket_items) >= target_count * 2:\n",
    "            # 随机抽取足够的题目\n",
    "            selected = rng.choice(bucket_items, size=target_count * 2, replace=False)\n",
    "            # 随机分配到两个子集\n",
    "            rng.shuffle(selected)\n",
    "            subset1_indices.extend(selected[:target_count])\n",
    "            subset2_indices.extend(selected[target_count:target_count * 2])\n",
    "        elif target_count > 0:\n",
    "            # 桶内题目不足，尽量均分\n",
    "            rng.shuffle(bucket_items)\n",
    "            mid = len(bucket_items) // 2\n",
    "            subset1_indices.extend(bucket_items[:mid])\n",
    "            subset2_indices.extend(bucket_items[mid:])\n",
    "    \n",
    "    # 如果子集大小不足，从剩余题目中随机补充\n",
    "    all_selected = set(subset1_indices + subset2_indices)\n",
    "    remaining_items = [i for i in range(len(item_difficulties)) if i not in all_selected]\n",
    "    \n",
    "    while len(subset1_indices) < subset_size and remaining_items:\n",
    "        idx = rng.choice(len(remaining_items))\n",
    "        subset1_indices.append(remaining_items.pop(idx))\n",
    "    \n",
    "    while len(subset2_indices) < subset_size and remaining_items:\n",
    "        idx = rng.choice(len(remaining_items))\n",
    "        subset2_indices.append(remaining_items.pop(idx))\n",
    "    \n",
    "    # 转换为原始数据中的索引\n",
    "    subset1_original = valid_indices[subset1_indices[:subset_size]]\n",
    "    subset2_original = valid_indices[subset2_indices[:subset_size]]\n",
    "    \n",
    "    return subset1_original, subset2_original, bucket_labels\n",
    "\n",
    "# 应用难度分位桶法\n",
    "subset1_bucket, subset2_bucket, difficulty_buckets = create_difficulty_bucket_subsets(\n",
    "    item_acc_valid, valid_indices, SUBSET_SIZE, random_state=random_state\n",
    ")\n",
    "\n",
    "print(\"方法一：难度分位桶法 - 完成\")\n",
    "print(f\"subset1_bucket大小: {len(subset1_bucket)}\")\n",
    "print(f\"subset2_bucket大小: {len(subset2_bucket)}\")\n",
    "print(f\"重叠题目数: {len(set(subset1_bucket) & set(subset2_bucket))}\")\n",
    "\n",
    "# 验证难度分布\n",
    "subset1_difficulties = item_acc[subset1_bucket]\n",
    "subset2_difficulties = item_acc[subset2_bucket]\n",
    "print(f\"subset1_bucket难度范围: {subset1_difficulties.min():.3f} - {subset1_difficulties.max():.3f}\")\n",
    "print(f\"subset2_bucket难度范围: {subset2_difficulties.min():.3f} - {subset2_difficulties.max():.3f}\")\n",
    "print(f\"subset1_bucket平均难度: {subset1_difficulties.mean():.3f}\")\n",
    "print(f\"subset2_bucket平均难度: {subset2_difficulties.mean():.3f}\")\n",
    "\n",
    "# 验证方法一是否排除了指定科目（应该已经通过valid_indices排除）\n",
    "bucket_subjects1 = df_cn.loc[subset1_bucket, 'Subject'].values\n",
    "bucket_subjects2 = df_cn.loc[subset2_bucket, 'Subject'].values\n",
    "excluded_in_bucket1 = [s for s in bucket_subjects1 if s in excluded_subjects]\n",
    "excluded_in_bucket2 = [s for s in bucket_subjects2 if s in excluded_subjects]\n",
    "print(f\"方法一中包含的排除科目: subset1_bucket: {excluded_in_bucket1}, subset2_bucket: {excluded_in_bucket2}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7972e31",
   "metadata": {},
   "source": [
    "### 方法二：IRT聚类法\n",
    "\n",
    "使用题目的IRT特征（难度和区分度）进行K-Means聚类，找到300个簇中心，然后为每个簇选择距离中心最近的2个题目，随机分配到两个子集。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "787b62d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IRT特征矩阵形状: (10217, 11)\n",
      "区分度范围: -5.049 - 7.334\n",
      "难度范围: -2.978 - 2.676\n",
      "聚类完成，共300个簇\n",
      "方法二：IRT聚类法 - 完成\n",
      "subset1_irt大小: 300\n",
      "subset2_irt大小: 300\n",
      "重叠题目数: 0\n",
      "subset1_irt区分度均值: 1.577\n",
      "subset2_irt区分度均值: 1.585\n",
      "subset1_irt难度均值: -0.141\n",
      "subset2_irt难度均值: -0.174\n",
      "方法二中包含的排除科目: subset1_irt: [], subset2_irt: []\n"
     ]
    }
   ],
   "source": [
    "def create_irt_clustering_subsets(valid_indices, subset_size, random_state=42):\n",
    "    \"\"\"\n",
    "    基于IRT聚类法创建两个不重叠的子集\n",
    "    \n",
    "    参数:\n",
    "    - valid_indices: 有效题目在原始数据中的索引\n",
    "    - subset_size: 每个子集的大小\n",
    "    - random_state: 随机种子\n",
    "    \n",
    "    返回:\n",
    "    - subset1_indices, subset2_indices: 两个子集在原始数据中的索引\n",
    "    \"\"\"\n",
    "    rng = np.random.RandomState(random_state)\n",
    "    \n",
    "    # 加载IRT参数\n",
    "    A, B, _ = load_irt_parameters('data/irt_model/')\n",
    "    \n",
    "    # 构建IRT特征矩阵：每行代表一个题目，列为[区分度, 难度]\n",
    "    irt_features = np.vstack((A.squeeze(), B.squeeze())).T\n",
    "    \n",
    "    # 只使用有效题目的IRT特征\n",
    "    irt_features_valid = irt_features[valid_indices]\n",
    "    \n",
    "    print(f\"IRT特征矩阵形状: {irt_features_valid.shape}\")\n",
    "    print(f\"区分度范围: {irt_features_valid[:, 0].min():.3f} - {irt_features_valid[:, 0].max():.3f}\")\n",
    "    print(f\"难度范围: {irt_features_valid[:, 1].min():.3f} - {irt_features_valid[:, 1].max():.3f}\")\n",
    "    \n",
    "    # 进行K-Means聚类，目标是300个簇\n",
    "    kmeans = KMeans(n_clusters=subset_size, n_init=10, random_state=random_state)\n",
    "    cluster_labels = kmeans.fit_predict(irt_features_valid)\n",
    "    cluster_centers = kmeans.cluster_centers_\n",
    "    \n",
    "    print(f\"聚类完成，共{len(np.unique(cluster_labels))}个簇\")\n",
    "    \n",
    "    # 为每个簇找到距离中心最近的2个题目（排除指定科目）\n",
    "    subset1_indices = []\n",
    "    subset2_indices = []\n",
    "    \n",
    "    # 获取每个有效题目的科目信息\n",
    "    subjects_valid = df_cn.loc[valid_indices, 'Subject'].values\n",
    "    \n",
    "    for cluster_id in range(subset_size):\n",
    "        # 找到属于当前簇的所有题目\n",
    "        cluster_mask = cluster_labels == cluster_id\n",
    "        cluster_items = np.where(cluster_mask)[0]\n",
    "        \n",
    "        if len(cluster_items) == 0:\n",
    "            continue\n",
    "        \n",
    "        # 计算簇内所有题目到中心的距离\n",
    "        cluster_features = irt_features_valid[cluster_items]\n",
    "        center = cluster_centers[cluster_id]\n",
    "        distances = np.linalg.norm(cluster_features - center, axis=1)\n",
    "        \n",
    "        # 按距离排序，找到不属于排除科目的最近的2个题目\n",
    "        sorted_indices = np.argsort(distances)\n",
    "        valid_items = []\n",
    "        \n",
    "        for idx in sorted_indices:\n",
    "            item_idx = cluster_items[idx]\n",
    "            item_subject = subjects_valid[item_idx]\n",
    "            \n",
    "            # 检查科目是否在排除列表中\n",
    "            if item_subject not in excluded_subjects:\n",
    "                valid_items.append(item_idx)\n",
    "                \n",
    "            # 找到2个有效题目就停止\n",
    "            if len(valid_items) >= 2:\n",
    "                break\n",
    "        \n",
    "        # 分配找到的有效题目\n",
    "        if len(valid_items) >= 2:\n",
    "            # 随机分配到两个子集\n",
    "            rng.shuffle(valid_items)\n",
    "            subset1_indices.append(valid_items[0])\n",
    "            subset2_indices.append(valid_items[1])\n",
    "        elif len(valid_items) == 1:\n",
    "            # 只有一个有效题目，随机分配\n",
    "            if rng.random() < 0.5:\n",
    "                subset1_indices.append(valid_items[0])\n",
    "            else:\n",
    "                subset2_indices.append(valid_items[0])\n",
    "        # 如果没有找到有效题目，跳过这个簇\n",
    "    \n",
    "    # 如果某个子集大小不足，从另一个子集中随机移动一些题目\n",
    "    while len(subset1_indices) < subset_size and len(subset2_indices) > 0:\n",
    "        idx = rng.choice(len(subset2_indices))\n",
    "        subset1_indices.append(subset2_indices.pop(idx))\n",
    "    \n",
    "    while len(subset2_indices) < subset_size and len(subset1_indices) > subset_size:\n",
    "        idx = rng.choice(len(subset1_indices[subset_size:]))\n",
    "        subset2_indices.append(subset1_indices.pop(subset_size + idx))\n",
    "    \n",
    "    # 转换为原始数据中的索引\n",
    "    subset1_original = valid_indices[subset1_indices[:subset_size]]\n",
    "    subset2_original = valid_indices[subset2_indices[:subset_size]]\n",
    "    \n",
    "    return subset1_original, subset2_original, cluster_labels, cluster_centers\n",
    "\n",
    "# 应用IRT聚类法\n",
    "subset1_irt, subset2_irt, irt_clusters, irt_centers = create_irt_clustering_subsets(\n",
    "    valid_indices, SUBSET_SIZE, random_state=random_state\n",
    ")\n",
    "\n",
    "print(\"方法二：IRT聚类法 - 完成\")\n",
    "print(f\"subset1_irt大小: {len(subset1_irt)}\")\n",
    "print(f\"subset2_irt大小: {len(subset2_irt)}\")\n",
    "print(f\"重叠题目数: {len(set(subset1_irt) & set(subset2_irt))}\")\n",
    "\n",
    "# 验证IRT特征分布\n",
    "# 加载IRT参数用于验证\n",
    "A, B, _ = load_irt_parameters('data/irt_model/')\n",
    "irt_features_all = np.vstack((A.squeeze(), B.squeeze())).T\n",
    "subset1_irt_features = irt_features_all[subset1_irt]\n",
    "subset2_irt_features = irt_features_all[subset2_irt]\n",
    "\n",
    "print(f\"subset1_irt区分度均值: {subset1_irt_features[:, 0].mean():.3f}\")\n",
    "print(f\"subset2_irt区分度均值: {subset2_irt_features[:, 0].mean():.3f}\")\n",
    "print(f\"subset1_irt难度均值: {subset1_irt_features[:, 1].mean():.3f}\")\n",
    "print(f\"subset2_irt难度均值: {subset2_irt_features[:, 1].mean():.3f}\")\n",
    "\n",
    "# 验证方法二是否排除了指定科目\n",
    "irt_subjects1 = df_cn.loc[subset1_irt, 'Subject'].values\n",
    "irt_subjects2 = df_cn.loc[subset2_irt, 'Subject'].values\n",
    "excluded_in_irt1 = [s for s in irt_subjects1 if s in excluded_subjects]\n",
    "excluded_in_irt2 = [s for s in irt_subjects2 if s in excluded_subjects]\n",
    "print(f\"方法二中包含的排除科目: subset1_irt: {excluded_in_irt1}, subset2_irt: {excluded_in_irt2}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61fad58c",
   "metadata": {},
   "source": [
    "### 方法三：题目正误矩阵聚类法\n",
    "\n",
    "使用所有模型对所有题目的作答0/1矩阵进行K-Means聚类，找到300个簇中心，然后为每个簇选择距离中心最近的2个题目，随机分配到两个子集。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5273ac14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "响应矩阵形状: (10217, 295)\n",
      "平均正确率: 0.575\n",
      "聚类完成，共300个簇\n",
      "方法三：题目正误矩阵聚类法 - 完成\n",
      "subset1_matrix大小: 300\n",
      "subset2_matrix大小: 292\n",
      "重叠题目数: 0\n",
      "subset1_matrix平均正确率: 0.517\n",
      "subset2_matrix平均正确率: 0.510\n",
      "subset1_matrix难度标准差: 0.242\n",
      "subset2_matrix难度标准差: 0.242\n"
     ]
    }
   ],
   "source": [
    "def create_response_matrix_clustering_subsets(Y_train, valid_indices, subset_size, random_state=42):\n",
    "    \"\"\"\n",
    "    基于题目正误矩阵聚类法创建两个不重叠的子集\n",
    "    \n",
    "    参数:\n",
    "    - Y_train: 训练集模型响应矩阵 (模型数, 题目数)\n",
    "    - valid_indices: 有效题目在原始数据中的索引\n",
    "    - subset_size: 每个子集的大小\n",
    "    - random_state: 随机种子\n",
    "    \n",
    "    返回:\n",
    "    - subset1_indices, subset2_indices: 两个子集在原始数据中的索引\n",
    "    \"\"\"\n",
    "    rng = np.random.RandomState(random_state)\n",
    "    \n",
    "    # 获取MMLU训练数据\n",
    "    Y_mmlu_train = Y_train[:, scenarios_position['mmlu']]  # 形状: (295个训练模型, 14042个MMLU题目)\n",
    "    \n",
    "    # 只使用有效题目\n",
    "    Y_mmlu_train_valid = Y_mmlu_train[:, valid_indices]  # 形状: (295, 有效题目数)\n",
    "    \n",
    "    # 转置矩阵，使每行代表一个题目，每列代表一个模型的响应\n",
    "    response_matrix = Y_mmlu_train_valid.T  # 形状: (有效题目数, 295个模型)\n",
    "    \n",
    "    print(f\"响应矩阵形状: {response_matrix.shape}\")\n",
    "    print(f\"平均正确率: {response_matrix.mean():.3f}\")\n",
    "    \n",
    "    # 进行K-Means聚类，目标是300个簇\n",
    "    kmeans = KMeans(n_clusters=subset_size, n_init=10, random_state=random_state)\n",
    "    cluster_labels = kmeans.fit_predict(response_matrix)\n",
    "    cluster_centers = kmeans.cluster_centers_\n",
    "    \n",
    "    print(f\"聚类完成，共{len(np.unique(cluster_labels))}个簇\")\n",
    "    \n",
    "    # 为每个簇找到距离中心最近的2个题目（排除指定科目）\n",
    "    subset1_indices = []\n",
    "    subset2_indices = []\n",
    "    \n",
    "    # 获取每个有效题目的科目信息\n",
    "    subjects_valid = df_cn.loc[valid_indices, 'Subject'].values\n",
    "    \n",
    "    for cluster_id in range(subset_size):\n",
    "        # 找到属于当前簇的所有题目\n",
    "        cluster_mask = cluster_labels == cluster_id\n",
    "        cluster_items = np.where(cluster_mask)[0]\n",
    "        \n",
    "        if len(cluster_items) == 0:\n",
    "            continue\n",
    "        \n",
    "        # 计算簇内所有题目到中心的距离\n",
    "        cluster_responses = response_matrix[cluster_items]\n",
    "        center = cluster_centers[cluster_id]\n",
    "        distances = np.linalg.norm(cluster_responses - center, axis=1)\n",
    "        \n",
    "        # 按距离排序，找到不属于排除科目的最近的2个题目\n",
    "        sorted_indices = np.argsort(distances)\n",
    "        valid_items = []\n",
    "        \n",
    "        for idx in sorted_indices:\n",
    "            item_idx = cluster_items[idx]\n",
    "            item_subject = subjects_valid[item_idx]\n",
    "            \n",
    "            # 检查科目是否在排除列表中\n",
    "            if item_subject not in excluded_subjects:\n",
    "                valid_items.append(item_idx)\n",
    "                \n",
    "            # 找到2个有效题目就停止\n",
    "            if len(valid_items) >= 2:\n",
    "                break\n",
    "        \n",
    "        # 分配找到的有效题目\n",
    "        if len(valid_items) >= 2:\n",
    "            # 随机分配到两个子集\n",
    "            rng.shuffle(valid_items)\n",
    "            subset1_indices.append(valid_items[0])\n",
    "            subset2_indices.append(valid_items[1])\n",
    "        elif len(valid_items) == 1:\n",
    "            # 只有一个有效题目，随机分配\n",
    "            if rng.random() < 0.5:\n",
    "                subset1_indices.append(valid_items[0])\n",
    "            else:\n",
    "                subset2_indices.append(valid_items[0])\n",
    "        # 如果没有找到有效题目，跳过这个簇\n",
    "    \n",
    "    # 如果某个子集大小不足，从另一个子集中随机移动一些题目\n",
    "    while len(subset1_indices) < subset_size and len(subset2_indices) > 0:\n",
    "        idx = rng.choice(len(subset2_indices))\n",
    "        subset1_indices.append(subset2_indices.pop(idx))\n",
    "    \n",
    "    while len(subset2_indices) < subset_size and len(subset1_indices) > subset_size:\n",
    "        idx = rng.choice(len(subset1_indices[subset_size:]))\n",
    "        subset2_indices.append(subset1_indices.pop(subset_size + idx))\n",
    "    \n",
    "    # 转换为原始数据中的索引\n",
    "    subset1_original = valid_indices[subset1_indices[:subset_size]]\n",
    "    subset2_original = valid_indices[subset2_indices[:subset_size]]\n",
    "    \n",
    "    return subset1_original, subset2_original, cluster_labels, cluster_centers\n",
    "\n",
    "# 应用题目正误矩阵聚类法\n",
    "subset1_matrix, subset2_matrix, matrix_clusters, matrix_centers = create_response_matrix_clustering_subsets(\n",
    "    Y_train, valid_indices, SUBSET_SIZE, random_state=random_state\n",
    ")\n",
    "\n",
    "print(\"方法三：题目正误矩阵聚类法 - 完成\")\n",
    "print(f\"subset1_matrix大小: {len(subset1_matrix)}\")\n",
    "print(f\"subset2_matrix大小: {len(subset2_matrix)}\")\n",
    "print(f\"重叠题目数: {len(set(subset1_matrix) & set(subset2_matrix))}\")\n",
    "\n",
    "# 验证响应模式分布\n",
    "Y_mmlu_train = Y_train[:, scenarios_position['mmlu']]\n",
    "subset1_matrix_responses = Y_mmlu_train[:, subset1_matrix]\n",
    "subset2_matrix_responses = Y_mmlu_train[:, subset2_matrix]\n",
    "\n",
    "print(f\"subset1_matrix平均正确率: {subset1_matrix_responses.mean():.3f}\")\n",
    "print(f\"subset2_matrix平均正确率: {subset2_matrix_responses.mean():.3f}\")\n",
    "print(f\"subset1_matrix难度标准差: {subset1_matrix_responses.mean(axis=0).std():.3f}\")\n",
    "print(f\"subset2_matrix难度标准差: {subset2_matrix_responses.mean(axis=0).std():.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d30629ee",
   "metadata": {},
   "source": [
    "## 综合评估与比较\n",
    "\n",
    "现在我们将对生成的6个子集进行全面评估：\n",
    "1. 计算每个子集上的模型预测准确率\n",
    "2. 与完整MMLU数据集的准确率进行比较\n",
    "3. 计算每种方法内部两个子集之间的准确率差异\n",
    "4. 评估哪种方法最稳定和具有代表性\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fead3bd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 完整MMLU基准表现 ===\n",
      "完整MMLU平均准确率: 0.6987\n",
      "完整MMLU准确率标准差: 0.0756\n",
      "完整MMLU准确率范围: 0.3654 - 0.8306\n",
      "\n",
      "=== 各子集表现 ===\n",
      "\n",
      "subset1_bucket:\n",
      "  平均准确率: 0.6840\n",
      "  标准差: 0.0829\n",
      "  与完整MMLU的差异: 0.0147\n",
      "  相关系数: 0.9823\n",
      "\n",
      "subset2_bucket:\n",
      "  平均准确率: 0.7044\n",
      "  标准差: 0.0809\n",
      "  与完整MMLU的差异: 0.0057\n",
      "  相关系数: 0.9800\n",
      "\n",
      "subset1_irt:\n",
      "  平均准确率: 0.5859\n",
      "  标准差: 0.0977\n",
      "  与完整MMLU的差异: 0.1128\n",
      "  相关系数: 0.9735\n",
      "\n",
      "subset2_irt:\n",
      "  平均准确率: 0.5871\n",
      "  标准差: 0.0931\n",
      "  与完整MMLU的差异: 0.1115\n",
      "  相关系数: 0.9738\n",
      "\n",
      "subset1_matrix:\n",
      "  平均准确率: 0.6892\n",
      "  标准差: 0.0820\n",
      "  与完整MMLU的差异: 0.0095\n",
      "  相关系数: 0.9842\n",
      "\n",
      "subset2_matrix:\n",
      "  平均准确率: 0.6481\n",
      "  标准差: 0.0820\n",
      "  与完整MMLU的差异: 0.0506\n",
      "  相关系数: 0.9720\n",
      "\n",
      "=== 方法内部一致性分析 ===\n",
      "\n",
      "BUCKET方法一致性:\n",
      "  两子集平均准确率差异: 0.02037\n",
      "  两子集标准差差异: 0.00198\n",
      "  两子集相关系数: 0.9555\n",
      "  模型间平均差异: 0.02654\n",
      "  模型间最大差异: 0.09191\n",
      "\n",
      "IRT方法一致性:\n",
      "  两子集平均准确率差异: 0.00128\n",
      "  两子集标准差差异: 0.00463\n",
      "  两子集相关系数: 0.9727\n",
      "  模型间平均差异: 0.01833\n",
      "  模型间最大差异: 0.08059\n",
      "\n",
      "MATRIX方法一致性:\n",
      "  两子集平均准确率差异: 0.04108\n",
      "  两子集标准差差异: 0.00002\n",
      "  两子集相关系数: 0.9534\n",
      "  模型间平均差异: 0.04256\n",
      "  模型间最大差异: 0.10255\n",
      "\n",
      "=== 方法代表性分析 ===\n",
      "\n",
      "BUCKET方法代表性:\n",
      "  平均相关系数: 0.9811\n",
      "  平均准确率差异: 0.01019\n",
      "  平均标准差差异: 0.00628\n",
      "\n",
      "IRT方法代表性:\n",
      "  平均相关系数: 0.9737\n",
      "  平均准确率差异: 0.11216\n",
      "  平均标准差差异: 0.01980\n",
      "\n",
      "MATRIX方法代表性:\n",
      "  平均相关系数: 0.9781\n",
      "  平均准确率差异: 0.03004\n",
      "  平均标准差差异: 0.00641\n",
      "\n",
      "=== 数据保存 ===\n",
      "评估结果已计算完成并存储在evaluation_results中\n"
     ]
    }
   ],
   "source": [
    "# 收集所有子集\n",
    "all_subsets = {\n",
    "    'subset1_bucket': subset1_bucket,\n",
    "    'subset2_bucket': subset2_bucket,\n",
    "    'subset1_irt': subset1_irt,\n",
    "    'subset2_irt': subset2_irt,\n",
    "    'subset1_matrix': subset1_matrix,\n",
    "    'subset2_matrix': subset2_matrix\n",
    "}\n",
    "\n",
    "# 计算完整MMLU（排除指定科目后）的基准准确率\n",
    "Y_mmlu_valid_all = Y[:, valid_indices]  # 所有模型在有效题目上的响应\n",
    "full_mmlu_acc = Y_mmlu_valid_all.mean(axis=1)  # 每个模型在完整有效MMLU上的准确率\n",
    "\n",
    "print(\"=== 完整MMLU基准表现 ===\")\n",
    "print(f\"完整MMLU平均准确率: {full_mmlu_acc.mean():.4f}\")\n",
    "print(f\"完整MMLU准确率标准差: {full_mmlu_acc.std():.4f}\")\n",
    "print(f\"完整MMLU准确率范围: {full_mmlu_acc.min():.4f} - {full_mmlu_acc.max():.4f}\")\n",
    "\n",
    "# 计算每个子集的准确率\n",
    "subset_accuracies = {}\n",
    "print(\"\\n=== 各子集表现 ===\")\n",
    "\n",
    "for subset_name, subset_indices in all_subsets.items():\n",
    "    # 所有模型在该子集上的响应\n",
    "    subset_responses = Y[:, subset_indices]\n",
    "    # 每个模型在该子集上的准确率\n",
    "    subset_acc = subset_responses.mean(axis=1)\n",
    "    subset_accuracies[subset_name] = subset_acc\n",
    "    \n",
    "    print(f\"\\n{subset_name}:\")\n",
    "    print(f\"  平均准确率: {subset_acc.mean():.4f}\")\n",
    "    print(f\"  标准差: {subset_acc.std():.4f}\")\n",
    "    print(f\"  与完整MMLU的差异: {abs(subset_acc.mean() - full_mmlu_acc.mean()):.4f}\")\n",
    "    print(f\"  相关系数: {np.corrcoef(subset_acc, full_mmlu_acc)[0,1]:.4f}\")\n",
    "\n",
    "# 计算每种方法内部的一致性\n",
    "print(\"\\n=== 方法内部一致性分析 ===\")\n",
    "\n",
    "methods = ['bucket', 'irt', 'matrix']\n",
    "method_consistency = {}\n",
    "\n",
    "for method in methods:\n",
    "    subset1_acc = subset_accuracies[f'subset1_{method}']\n",
    "    subset2_acc = subset_accuracies[f'subset2_{method}']\n",
    "    \n",
    "    # 计算两个子集间的差异\n",
    "    diff_mean = abs(subset1_acc.mean() - subset2_acc.mean())\n",
    "    diff_std = abs(subset1_acc.std() - subset2_acc.std())\n",
    "    correlation = np.corrcoef(subset1_acc, subset2_acc)[0,1]\n",
    "    \n",
    "    # 计算每个模型在两个子集上的准确率差异\n",
    "    model_diffs = abs(subset1_acc - subset2_acc)\n",
    "    avg_model_diff = model_diffs.mean()\n",
    "    max_model_diff = model_diffs.max()\n",
    "    \n",
    "    method_consistency[method] = {\n",
    "        'mean_diff': diff_mean,\n",
    "        'std_diff': diff_std,\n",
    "        'correlation': correlation,\n",
    "        'avg_model_diff': avg_model_diff,\n",
    "        'max_model_diff': max_model_diff\n",
    "    }\n",
    "    \n",
    "    print(f\"\\n{method.upper()}方法一致性:\")\n",
    "    print(f\"  两子集平均准确率差异: {diff_mean:.5f}\")\n",
    "    print(f\"  两子集标准差差异: {diff_std:.5f}\")\n",
    "    print(f\"  两子集相关系数: {correlation:.4f}\")\n",
    "    print(f\"  模型间平均差异: {avg_model_diff:.5f}\")\n",
    "    print(f\"  模型间最大差异: {max_model_diff:.5f}\")\n",
    "\n",
    "# 计算每种方法与完整MMLU的代表性\n",
    "print(\"\\n=== 方法代表性分析 ===\")\n",
    "\n",
    "method_representativeness = {}\n",
    "\n",
    "for method in methods:\n",
    "    subset1_acc = subset_accuracies[f'subset1_{method}']\n",
    "    subset2_acc = subset_accuracies[f'subset2_{method}']\n",
    "    \n",
    "    # 两个子集与完整MMLU的相关性\n",
    "    corr1 = np.corrcoef(subset1_acc, full_mmlu_acc)[0,1]\n",
    "    corr2 = np.corrcoef(subset2_acc, full_mmlu_acc)[0,1]\n",
    "    avg_corr = (corr1 + corr2) / 2\n",
    "    \n",
    "    # 两个子集与完整MMLU的平均准确率差异\n",
    "    diff1 = abs(subset1_acc.mean() - full_mmlu_acc.mean())\n",
    "    diff2 = abs(subset2_acc.mean() - full_mmlu_acc.mean())\n",
    "    avg_diff = (diff1 + diff2) / 2\n",
    "    \n",
    "    # 标准差差异\n",
    "    std_diff1 = abs(subset1_acc.std() - full_mmlu_acc.std())\n",
    "    std_diff2 = abs(subset2_acc.std() - full_mmlu_acc.std())\n",
    "    avg_std_diff = (std_diff1 + std_diff2) / 2\n",
    "    \n",
    "    method_representativeness[method] = {\n",
    "        'avg_correlation': avg_corr,\n",
    "        'avg_mean_diff': avg_diff,\n",
    "        'avg_std_diff': avg_std_diff\n",
    "    }\n",
    "    \n",
    "    print(f\"\\n{method.upper()}方法代表性:\")\n",
    "    print(f\"  平均相关系数: {avg_corr:.4f}\")\n",
    "    print(f\"  平均准确率差异: {avg_diff:.5f}\")\n",
    "    print(f\"  平均标准差差异: {avg_std_diff:.5f}\")\n",
    "\n",
    "print(\"\\n=== 数据保存 ===\")\n",
    "\n",
    "# 保存结果供后续分析\n",
    "evaluation_results = {\n",
    "    'full_mmlu_accuracy': {\n",
    "        'mean': float(full_mmlu_acc.mean()),\n",
    "        'std': float(full_mmlu_acc.std()),\n",
    "        'min': float(full_mmlu_acc.min()),\n",
    "        'max': float(full_mmlu_acc.max())\n",
    "    },\n",
    "    'subset_accuracies': {name: {'mean': float(acc.mean()), 'std': float(acc.std())} \n",
    "                         for name, acc in subset_accuracies.items()},\n",
    "    'method_consistency': method_consistency,\n",
    "    'method_representativeness': method_representativeness\n",
    "}\n",
    "\n",
    "print(\"评估结果已计算完成并存储在evaluation_results中\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9b87906d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 综合评分和方法排序 ===\n",
      "\n",
      "BUCKET方法评分:\n",
      "  一致性评分: 0.9685\n",
      "  代表性评分: 0.9863\n",
      "  综合评分: 0.9774\n",
      "\n",
      "IRT方法评分:\n",
      "  一致性评分: 0.9833\n",
      "  代表性评分: 0.9527\n",
      "  综合评分: 0.9680\n",
      "\n",
      "MATRIX方法评分:\n",
      "  一致性评分: 0.9573\n",
      "  代表性评分: 0.9790\n",
      "  综合评分: 0.9681\n",
      "\n",
      "=== 方法排序（从最佳到最差） ===\n",
      "1. BUCKET方法 - 综合评分: 0.9774\n",
      "2. MATRIX方法 - 综合评分: 0.9681\n",
      "3. IRT方法 - 综合评分: 0.9680\n",
      "\n",
      "=== 最佳方法：BUCKET方法详细分析 ===\n",
      "一致性指标:\n",
      "  两子集平均准确率差异: 0.02037\n",
      "  两子集相关系数: 0.9555\n",
      "  模型间平均差异: 0.02654\n",
      "\n",
      "代表性指标:\n",
      "  与完整MMLU平均相关系数: 0.9811\n",
      "  与完整MMLU平均准确率差异: 0.01019\n",
      "\n",
      "最佳方法子集索引:\n",
      "subset1_bucket: 300个题目\n",
      "subset2_bucket: 300个题目\n",
      "\n",
      "=== 结论和建议 ===\n",
      "难度分位桶法表现最佳。这种方法简单易懂，基于题目难度进行分层抽样，\n",
      "能够很好地保持子集间的平衡，并且与原始数据集具有较好的代表性。\n",
      "\n",
      "推荐使用BUCKET方法生成的子集进行MMLU性能评估。\n"
     ]
    }
   ],
   "source": [
    "# 综合评分和排序\n",
    "print(\"=== 综合评分和方法排序 ===\")\n",
    "\n",
    "# 定义评分权重\n",
    "weights = {\n",
    "    'consistency': 0.5,      # 方法内部一致性权重\n",
    "    'representativeness': 0.5  # 代表性权重\n",
    "}\n",
    "\n",
    "method_scores = {}\n",
    "\n",
    "for method in methods:\n",
    "    consistency = method_consistency[method]\n",
    "    representativeness = method_representativeness[method]\n",
    "    \n",
    "    # 一致性评分（越小越好，需要取倒数并归一化）\n",
    "    consistency_score = (\n",
    "        (1 / (1 + consistency['mean_diff'])) * 0.3 +\n",
    "        (1 / (1 + consistency['avg_model_diff'])) * 0.3 +\n",
    "        consistency['correlation'] * 0.4\n",
    "    )\n",
    "    \n",
    "    # 代表性评分（越高越好）\n",
    "    representativeness_score = (\n",
    "        representativeness['avg_correlation'] * 0.5 +\n",
    "        (1 / (1 + representativeness['avg_mean_diff'])) * 0.3 +\n",
    "        (1 / (1 + representativeness['avg_std_diff'])) * 0.2\n",
    "    )\n",
    "    \n",
    "    # 综合评分\n",
    "    total_score = (\n",
    "        consistency_score * weights['consistency'] +\n",
    "        representativeness_score * weights['representativeness']\n",
    "    )\n",
    "    \n",
    "    method_scores[method] = {\n",
    "        'consistency_score': consistency_score,\n",
    "        'representativeness_score': representativeness_score,\n",
    "        'total_score': total_score\n",
    "    }\n",
    "    \n",
    "    print(f\"\\n{method.upper()}方法评分:\")\n",
    "    print(f\"  一致性评分: {consistency_score:.4f}\")\n",
    "    print(f\"  代表性评分: {representativeness_score:.4f}\")\n",
    "    print(f\"  综合评分: {total_score:.4f}\")\n",
    "\n",
    "# 排序方法\n",
    "sorted_methods = sorted(method_scores.items(), key=lambda x: x[1]['total_score'], reverse=True)\n",
    "\n",
    "print(\"\\n=== 方法排序（从最佳到最差） ===\")\n",
    "for i, (method, scores) in enumerate(sorted_methods, 1):\n",
    "    print(f\"{i}. {method.upper()}方法 - 综合评分: {scores['total_score']:.4f}\")\n",
    "\n",
    "# 详细分析最佳方法\n",
    "best_method = sorted_methods[0][0]\n",
    "print(f\"\\n=== 最佳方法：{best_method.upper()}方法详细分析 ===\")\n",
    "\n",
    "best_consistency = method_consistency[best_method]\n",
    "best_representativeness = method_representativeness[best_method]\n",
    "\n",
    "print(f\"一致性指标:\")\n",
    "print(f\"  两子集平均准确率差异: {best_consistency['mean_diff']:.5f}\")\n",
    "print(f\"  两子集相关系数: {best_consistency['correlation']:.4f}\")\n",
    "print(f\"  模型间平均差异: {best_consistency['avg_model_diff']:.5f}\")\n",
    "\n",
    "print(f\"\\n代表性指标:\")\n",
    "print(f\"  与完整MMLU平均相关系数: {best_representativeness['avg_correlation']:.4f}\")\n",
    "print(f\"  与完整MMLU平均准确率差异: {best_representativeness['avg_mean_diff']:.5f}\")\n",
    "\n",
    "# 输出最佳方法的子集\n",
    "print(f\"\\n最佳方法子集索引:\")\n",
    "print(f\"subset1_{best_method}: {len(all_subsets[f'subset1_{best_method}'])}个题目\")\n",
    "print(f\"subset2_{best_method}: {len(all_subsets[f'subset2_{best_method}'])}个题目\")\n",
    "\n",
    "print(\"\\n=== 结论和建议 ===\")\n",
    "if best_method == 'bucket':\n",
    "    print(\"难度分位桶法表现最佳。这种方法简单易懂，基于题目难度进行分层抽样，\")\n",
    "    print(\"能够很好地保持子集间的平衡，并且与原始数据集具有较好的代表性。\")\n",
    "elif best_method == 'irt':\n",
    "    print(\"IRT聚类法表现最佳。这种方法利用了题目的心理测量学特征（难度和区分度），\")\n",
    "    print(\"能够更精细地捕捉题目特性，生成的子集具有更好的测量特性。\")\n",
    "elif best_method == 'matrix':\n",
    "    print(\"题目正误矩阵聚类法表现最佳。这种方法基于模型的实际响应模式进行聚类，\")\n",
    "    print(\"能够识别具有相似响应模式的题目，生成的子集在评估不同模型时更加稳定。\")\n",
    "\n",
    "print(f\"\\n推荐使用{best_method.upper()}方法生成的子集进行MMLU性能评估。\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9c007053",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 最终汇总表格 ===\n",
      "    方法 两子集平均准确率差异 两子集相关系数 模型间平均差异 与完整MMLU相关系数 与完整MMLU准确率差异  一致性评分  代表性评分   综合评分  排名\n",
      "BUCKET    0.02037  0.9555 0.02654      0.9811      0.01019 0.9685 0.9863 0.9774   1\n",
      "MATRIX    0.04108  0.9534 0.04256      0.9781      0.03004 0.9573 0.9790 0.9681   2\n",
      "   IRT    0.00128  0.9727 0.01833      0.9737      0.11216 0.9833 0.9527 0.9680   3\n",
      "\n",
      "=== 子集准确率对比 ===\n",
      "            子集  平均准确率    标准差 与完整MMLU差异 与完整MMLU相关系数\n",
      "subset1_bucket 0.6840 0.0829    0.0147      0.9823\n",
      "subset2_bucket 0.7044 0.0809    0.0057      0.9800\n",
      "   subset1_irt 0.5859 0.0977    0.1128      0.9735\n",
      "   subset2_irt 0.5871 0.0931    0.1115      0.9738\n",
      "subset1_matrix 0.6892 0.0820    0.0095      0.9842\n",
      "subset2_matrix 0.6481 0.0820    0.0506      0.9720\n",
      "     Full_MMLU 0.6987 0.0756    0.0000      1.0000\n",
      "\n",
      "=== 最终选定的最佳子集 ===\n",
      "方法: BUCKET\n",
      "subset1_bucket: [1015, 1848, 12603, 2303, 1351, 9873, 932, 1898, 1670, 12498]... (共300题)\n",
      "subset2_bucket: [1074, 1771, 2182, 4117, 1449, 13092, 317, 4748, 1943, 3065]... (共300题)\n",
      "\n",
      "=== 任务完成 ===\n",
      "已成功实现三种MMLU子集生成方法并完成综合评估:\n",
      "1. ✅ 难度分位桶法\n",
      "2. ✅ IRT聚类法\n",
      "3. ✅ 题目正误矩阵聚类法\n",
      "4. ✅ 综合评估和方法比较\n",
      "5. ✅ 最佳方法推荐: BUCKET\n",
      "\n",
      "所有结果已保存在变量final_results中，可用于后续分析。\n"
     ]
    }
   ],
   "source": [
    "# 创建汇总表格用于可视化比较\n",
    "import pandas as pd\n",
    "\n",
    "print(\"=== 最终汇总表格 ===\")\n",
    "\n",
    "# 创建方法比较表\n",
    "comparison_data = []\n",
    "for method in methods:\n",
    "    consistency = method_consistency[method]\n",
    "    representativeness = method_representativeness[method]\n",
    "    scores = method_scores[method]\n",
    "    \n",
    "    comparison_data.append({\n",
    "        '方法': method.upper(),\n",
    "        '两子集平均准确率差异': f\"{consistency['mean_diff']:.5f}\",\n",
    "        '两子集相关系数': f\"{consistency['correlation']:.4f}\",\n",
    "        '模型间平均差异': f\"{consistency['avg_model_diff']:.5f}\",\n",
    "        '与完整MMLU相关系数': f\"{representativeness['avg_correlation']:.4f}\",\n",
    "        '与完整MMLU准确率差异': f\"{representativeness['avg_mean_diff']:.5f}\",\n",
    "        '一致性评分': f\"{scores['consistency_score']:.4f}\",\n",
    "        '代表性评分': f\"{scores['representativeness_score']:.4f}\",\n",
    "        '综合评分': f\"{scores['total_score']:.4f}\",\n",
    "        '排名': sorted_methods.index((method, scores)) + 1\n",
    "    })\n",
    "\n",
    "comparison_df = pd.DataFrame(comparison_data)\n",
    "comparison_df = comparison_df.sort_values('排名')\n",
    "\n",
    "print(comparison_df.to_string(index=False))\n",
    "\n",
    "# 创建子集准确率比较表\n",
    "print(\"\\n=== 子集准确率对比 ===\")\n",
    "accuracy_data = []\n",
    "for subset_name, subset_acc in subset_accuracies.items():\n",
    "    accuracy_data.append({\n",
    "        '子集': subset_name,\n",
    "        '平均准确率': f\"{subset_acc.mean():.4f}\",\n",
    "        '标准差': f\"{subset_acc.std():.4f}\",\n",
    "        '与完整MMLU差异': f\"{abs(subset_acc.mean() - full_mmlu_acc.mean()):.4f}\",\n",
    "        '与完整MMLU相关系数': f\"{np.corrcoef(subset_acc, full_mmlu_acc)[0,1]:.4f}\"\n",
    "    })\n",
    "\n",
    "# 添加完整MMLU基准\n",
    "accuracy_data.append({\n",
    "    '子集': 'Full_MMLU',\n",
    "    '平均准确率': f\"{full_mmlu_acc.mean():.4f}\",\n",
    "    '标准差': f\"{full_mmlu_acc.std():.4f}\",\n",
    "    '与完整MMLU差异': \"0.0000\",\n",
    "    '与完整MMLU相关系数': \"1.0000\"\n",
    "})\n",
    "\n",
    "accuracy_df = pd.DataFrame(accuracy_data)\n",
    "print(accuracy_df.to_string(index=False))\n",
    "\n",
    "# 保存最终结果\n",
    "final_results = {\n",
    "    'evaluation_date': pd.Timestamp.now().isoformat(),\n",
    "    'best_method': best_method,\n",
    "    'method_comparison': comparison_df.to_dict('records'),\n",
    "    'accuracy_comparison': accuracy_df.to_dict('records'),\n",
    "    'all_subsets': {name: indices.tolist() for name, indices in all_subsets.items()},\n",
    "    'evaluation_results': evaluation_results\n",
    "}\n",
    "\n",
    "# 输出所选子集的摘要信息\n",
    "print(f\"\\n=== 最终选定的最佳子集 ===\")\n",
    "print(f\"方法: {best_method.upper()}\")\n",
    "print(f\"subset1_{best_method}: {all_subsets[f'subset1_{best_method}'][:10].tolist()}... (共{len(all_subsets[f'subset1_{best_method}'])}题)\")\n",
    "print(f\"subset2_{best_method}: {all_subsets[f'subset2_{best_method}'][:10].tolist()}... (共{len(all_subsets[f'subset2_{best_method}'])}题)\")\n",
    "\n",
    "print(\"\\n=== 任务完成 ===\")\n",
    "print(\"已成功实现三种MMLU子集生成方法并完成综合评估:\")\n",
    "print(\"1. ✅ 难度分位桶法\")\n",
    "print(\"2. ✅ IRT聚类法\") \n",
    "print(\"3. ✅ 题目正误矩阵聚类法\")\n",
    "print(\"4. ✅ 综合评估和方法比较\")\n",
    "print(f\"5. ✅ 最佳方法推荐: {best_method.upper()}\")\n",
    "\n",
    "print(f\"\\n所有结果已保存在变量final_results中，可用于后续分析。\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f5b5de54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "导出完成，文件位置：\n",
      "- subset1_bucket: mmlu_subsets_csv\\mmlu_ZH-CN_subset1_bucket.csv\n",
      "- subset2_bucket: mmlu_subsets_csv\\mmlu_ZH-CN_subset2_bucket.csv\n",
      "- subset1_irt: mmlu_subsets_csv\\mmlu_ZH-CN_subset1_irt.csv\n",
      "- subset2_irt: mmlu_subsets_csv\\mmlu_ZH-CN_subset2_irt.csv\n",
      "- subset1_matrix: mmlu_subsets_csv\\mmlu_ZH-CN_subset1_matrix.csv\n",
      "- subset2_matrix: mmlu_subsets_csv\\mmlu_ZH-CN_subset2_matrix.csv\n"
     ]
    }
   ],
   "source": [
    "# 导出6个子集为与 mmlu_ZH-CN.csv 相同结构且按要求排序的CSV\n",
    "\n",
    "import os\n",
    "\n",
    "out_dir = 'mmlu_subsets_csv'\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "# 输出列保持与 mmlu_ZH-CN.csv 一致\n",
    "cols = ['ID', 'Question', 'A', 'B', 'C', 'D', 'Answer', 'Subject']\n",
    "\n",
    "# 子集名称与索引（这些变量已在上文生成）\n",
    "subsets_to_export = {\n",
    "    'subset1_bucket': subset1_bucket,\n",
    "    'subset2_bucket': subset2_bucket,\n",
    "    'subset1_irt': subset1_irt,\n",
    "    'subset2_irt': subset2_irt,\n",
    "    'subset1_matrix': subset1_matrix,\n",
    "    'subset2_matrix': subset2_matrix,\n",
    "}\n",
    "\n",
    "def export_subset_sorted(df_source, indices, path, cols):\n",
    "    df_sub = df_source.loc[indices, cols].copy()\n",
    "    # 确保按 Subject 升序、同一 Subject 内按 ID 降序\n",
    "    # 使用稳定排序以保证分组后次序稳定\n",
    "    df_sub = df_sub.sort_values(by=['Subject', 'ID'],\n",
    "                                ascending=[True, True],\n",
    "                                kind='mergesort')\n",
    "    df_sub.to_csv(path, index=False, encoding='utf-8')\n",
    "\n",
    "export_paths = {}\n",
    "for name, idxs in subsets_to_export.items():\n",
    "    filename = f\"mmlu_ZH-CN_{name}.csv\"\n",
    "    path = os.path.join(out_dir, filename)\n",
    "    export_subset_sorted(df_cn, idxs, path, cols)\n",
    "    export_paths[name] = path\n",
    "\n",
    "print(\"导出完成，文件位置：\")\n",
    "for name, path in export_paths.items():\n",
    "    print(f\"- {name}: {path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc317bc3",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[35]\u001b[39m\u001b[32m, line 64\u001b[39m\n\u001b[32m     60\u001b[39m \tsubset1_irt, subset2_irt, _, _ = create_irt_clustering_subsets(\n\u001b[32m     61\u001b[39m \t\tvalid_indices, SUBSET_SIZE, random_state=seed\n\u001b[32m     62\u001b[39m \t)\n\u001b[32m     63\u001b[39m \t\u001b[38;5;66;03m# 方法三：正误矩阵聚类法\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m64\u001b[39m \tsubset1_matrix, subset2_matrix, _, _ = \u001b[43mcreate_response_matrix_clustering_subsets\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     65\u001b[39m \u001b[43m\t\t\u001b[49m\u001b[43mY_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalid_indices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mSUBSET_SIZE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m=\u001b[49m\u001b[43mseed\u001b[49m\n\u001b[32m     66\u001b[39m \u001b[43m\t\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     68\u001b[39m all_subsets_seed = {\n\u001b[32m     69\u001b[39m \t\u001b[33m'\u001b[39m\u001b[33msubset1_bucket\u001b[39m\u001b[33m'\u001b[39m: subset1_bucket, \u001b[33m'\u001b[39m\u001b[33msubset2_bucket\u001b[39m\u001b[33m'\u001b[39m: subset2_bucket,\n\u001b[32m     70\u001b[39m \t\u001b[33m'\u001b[39m\u001b[33msubset1_irt\u001b[39m\u001b[33m'\u001b[39m: subset1_irt, \u001b[33m'\u001b[39m\u001b[33msubset2_irt\u001b[39m\u001b[33m'\u001b[39m: subset2_irt,\n\u001b[32m     71\u001b[39m \t\u001b[33m'\u001b[39m\u001b[33msubset1_matrix\u001b[39m\u001b[33m'\u001b[39m: subset1_matrix, \u001b[33m'\u001b[39m\u001b[33msubset2_matrix\u001b[39m\u001b[33m'\u001b[39m: subset2_matrix\n\u001b[32m     72\u001b[39m }\n\u001b[32m     74\u001b[39m \u001b[38;5;66;03m# 各子集准确率（对所有395个模型）\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[22]\u001b[39m\u001b[32m, line 30\u001b[39m, in \u001b[36mcreate_response_matrix_clustering_subsets\u001b[39m\u001b[34m(Y_train, valid_indices, subset_size, random_state)\u001b[39m\n\u001b[32m     28\u001b[39m \u001b[38;5;66;03m# 进行K-Means聚类，目标是300个簇\u001b[39;00m\n\u001b[32m     29\u001b[39m kmeans = KMeans(n_clusters=subset_size, n_init=\u001b[32m10\u001b[39m, random_state=random_state)\n\u001b[32m---> \u001b[39m\u001b[32m30\u001b[39m cluster_labels = \u001b[43mkmeans\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse_matrix\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     31\u001b[39m cluster_centers = kmeans.cluster_centers_\n\u001b[32m     33\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m聚类完成，共\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(np.unique(cluster_labels))\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m个簇\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\19119\\.conda\\envs\\TinyBenchEnv\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1071\u001b[39m, in \u001b[36m_BaseKMeans.fit_predict\u001b[39m\u001b[34m(self, X, y, sample_weight)\u001b[39m\n\u001b[32m   1048\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfit_predict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y=\u001b[38;5;28;01mNone\u001b[39;00m, sample_weight=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m   1049\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Compute cluster centers and predict cluster index for each sample.\u001b[39;00m\n\u001b[32m   1050\u001b[39m \n\u001b[32m   1051\u001b[39m \u001b[33;03m    Convenience method; equivalent to calling fit(X) followed by\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1069\u001b[39m \u001b[33;03m        Index of the cluster each sample belongs to.\u001b[39;00m\n\u001b[32m   1070\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1071\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m=\u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m.labels_\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\19119\\.conda\\envs\\TinyBenchEnv\\Lib\\site-packages\\sklearn\\base.py:1474\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1467\u001b[39m     estimator._validate_params()\n\u001b[32m   1469\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1470\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1471\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1472\u001b[39m     )\n\u001b[32m   1473\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1474\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\19119\\.conda\\envs\\TinyBenchEnv\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1525\u001b[39m, in \u001b[36mKMeans.fit\u001b[39m\u001b[34m(self, X, y, sample_weight)\u001b[39m\n\u001b[32m   1521\u001b[39m best_inertia, best_labels = \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1523\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m._n_init):\n\u001b[32m   1524\u001b[39m     \u001b[38;5;66;03m# Initialize centers\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1525\u001b[39m     centers_init = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_init_centroids\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1526\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1527\u001b[39m \u001b[43m        \u001b[49m\u001b[43mx_squared_norms\u001b[49m\u001b[43m=\u001b[49m\u001b[43mx_squared_norms\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1528\u001b[39m \u001b[43m        \u001b[49m\u001b[43minit\u001b[49m\u001b[43m=\u001b[49m\u001b[43minit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1529\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1530\u001b[39m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m=\u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1531\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1532\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.verbose:\n\u001b[32m   1533\u001b[39m         \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mInitialization complete\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\19119\\.conda\\envs\\TinyBenchEnv\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1021\u001b[39m, in \u001b[36m_BaseKMeans._init_centroids\u001b[39m\u001b[34m(self, X, x_squared_norms, init, random_state, sample_weight, init_size, n_centroids)\u001b[39m\n\u001b[32m   1018\u001b[39m     sample_weight = sample_weight[init_indices]\n\u001b[32m   1020\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(init, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m init == \u001b[33m\"\u001b[39m\u001b[33mk-means++\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m1021\u001b[39m     centers, _ = \u001b[43m_kmeans_plusplus\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1022\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1023\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_clusters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1024\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1025\u001b[39m \u001b[43m        \u001b[49m\u001b[43mx_squared_norms\u001b[49m\u001b[43m=\u001b[49m\u001b[43mx_squared_norms\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1026\u001b[39m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m=\u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1027\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1028\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(init, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m init == \u001b[33m\"\u001b[39m\u001b[33mrandom\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m   1029\u001b[39m     seeds = random_state.choice(\n\u001b[32m   1030\u001b[39m         n_samples,\n\u001b[32m   1031\u001b[39m         size=n_clusters,\n\u001b[32m   1032\u001b[39m         replace=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m   1033\u001b[39m         p=sample_weight / sample_weight.sum(),\n\u001b[32m   1034\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\19119\\.conda\\envs\\TinyBenchEnv\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:255\u001b[39m, in \u001b[36m_kmeans_plusplus\u001b[39m\u001b[34m(X, n_clusters, x_squared_norms, sample_weight, random_state, n_local_trials)\u001b[39m\n\u001b[32m    252\u001b[39m np.clip(candidate_ids, \u001b[38;5;28;01mNone\u001b[39;00m, closest_dist_sq.size - \u001b[32m1\u001b[39m, out=candidate_ids)\n\u001b[32m    254\u001b[39m \u001b[38;5;66;03m# Compute distances to center candidates\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m255\u001b[39m distance_to_candidates = \u001b[43m_euclidean_distances\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    256\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcandidate_ids\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_norm_squared\u001b[49m\u001b[43m=\u001b[49m\u001b[43mx_squared_norms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msquared\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[32m    257\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    259\u001b[39m \u001b[38;5;66;03m# update closest distances squared and potential for each candidate\u001b[39;00m\n\u001b[32m    260\u001b[39m np.minimum(closest_dist_sq, distance_to_candidates, out=distance_to_candidates)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\19119\\.conda\\envs\\TinyBenchEnv\\Lib\\site-packages\\sklearn\\metrics\\pairwise.py:382\u001b[39m, in \u001b[36m_euclidean_distances\u001b[39m\u001b[34m(X, Y, X_norm_squared, Y_norm_squared, squared)\u001b[39m\n\u001b[32m    379\u001b[39m     distances = _euclidean_distances_upcast(X, XX, Y, YY)\n\u001b[32m    380\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    381\u001b[39m     \u001b[38;5;66;03m# if dtype is already float64, no need to chunk and upcast\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m382\u001b[39m     distances = -\u001b[32m2\u001b[39m * \u001b[43msafe_sparse_dot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m.\u001b[49m\u001b[43mT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdense_output\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    383\u001b[39m     distances += XX\n\u001b[32m    384\u001b[39m     distances += YY\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\19119\\.conda\\envs\\TinyBenchEnv\\Lib\\site-packages\\sklearn\\utils\\extmath.py:211\u001b[39m, in \u001b[36msafe_sparse_dot\u001b[39m\u001b[34m(a, b, dense_output)\u001b[39m\n\u001b[32m    207\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    208\u001b[39m     ret = a @ b\n\u001b[32m    210\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m--> \u001b[39m\u001b[32m211\u001b[39m     \u001b[43msparse\u001b[49m\u001b[43m.\u001b[49m\u001b[43missparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    212\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m sparse.issparse(b)\n\u001b[32m    213\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m dense_output\n\u001b[32m    214\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(ret, \u001b[33m\"\u001b[39m\u001b[33mtoarray\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    215\u001b[39m ):\n\u001b[32m    216\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m ret.toarray()\n\u001b[32m    217\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m ret\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\19119\\.conda\\envs\\TinyBenchEnv\\Lib\\site-packages\\scipy\\_lib\\_sparse.py:10\u001b[39m, in \u001b[36missparse\u001b[39m\u001b[34m(x)\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mSparseABC\u001b[39;00m(ABC):\n\u001b[32m      7\u001b[39m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34missparse\u001b[39m(x):\n\u001b[32m     11\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Is `x` of a sparse array or sparse matrix type?\u001b[39;00m\n\u001b[32m     12\u001b[39m \n\u001b[32m     13\u001b[39m \u001b[33;03m    Parameters\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     39\u001b[39m \u001b[33;03m    False\u001b[39;00m\n\u001b[32m     40\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m     41\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, SparseABC)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# 多随机种子复现实验（10个random_state）：对三种方法进行稳定性与代表性评估\n",
    "import io, contextlib, os, json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# 可调整的种子集合\n",
    "seeds = [0, 1, 2, 3, 4, 5, 6, 7, 8, 42]\n",
    "SUBSET_SIZE = 300\n",
    "\n",
    "# 基准：完整（排除科目后的）MMLU表现\n",
    "# Y shape: 模型数量，题目数量\n",
    "# full_mmlu_acc：每个模型在筛选的MMLU的准确率\n",
    "Y_mmlu_valid_all = Y[:, valid_indices]\n",
    "full_mmlu_acc = Y_mmlu_valid_all.mean(axis=1)\n",
    "\n",
    "def compute_method_total_score(consistency, representativeness, weights):\n",
    "\t# consistency：子集间的consistency\n",
    "\t# mean_diff: 对同一个方法在同一个随机种子下，两个子集的模型准确率均值（395个模型的准确率算平均）之差的绝对值\n",
    "\t# avg_model_diff: 与mean_diff相比，会算逐模型的准确率差的绝对值，会累积差异幅度\n",
    "\t# mean_diff是两个平均数（子集1的总准确率-子集2的总准确率）之差的绝对值\n",
    "\t# avg_model_diff是395个模型的准确率之差的绝对值之和的平均值，比mean_diff大\n",
    "\t# consistency存储两个子集间的一致性信息，repre存储与筛选后全集的关系\n",
    "\t# correlation：r = cov(a,b) / (sigma_a*sigma_b),cov(a,b)= (1/n)∑(a_i − μ_a)(b_i − μ_b)\n",
    "\t# a,b 两个子集的准确率，(395,), σ_a,σ_b为各自标准差( σ_a = sqrt((1/n)∑(a_i − μ_a)^2))\n",
    "\t# σ_a和sigma_b不能为0\n",
    "\t# consistency也是同个method同个seed。10个seed也有10个值\n",
    "\n",
    "\t# representativeness：两个子集与总集的repre的和\n",
    "\t# avg_correlation: 两个子集与全集的平均相关性.两个子集和全集的shape都为（395，）\n",
    "\t# 与上面的corr的区别是，子集各自与全集算Pierson corr coeff，再加和除以2（mean）\n",
    "\t# avg_mean_diff: 两个自己的各自准确率与总集的准确率的差值绝对值的平均值\n",
    "\t# diff1 = abs(subset1_acc.mean() - full_mmlu_acc.mean())\n",
    "\t# diff2 = abs(subset2_acc.mean() - full_mmlu_acc.mean())\n",
    "\t# avg_mean_diff = (diff1 + diff2) / 2\n",
    "\t# avg_std_diff\n",
    "\t# std1 = abs(a1.std() - full_mmlu_acc.std())\n",
    "\t# std2 = abs(a2.std() - full_mmlu_acc.std())\n",
    "\t# avg_std_diff = (std1 + std2) / 2\n",
    "\n",
    "\treturn (\n",
    "\t\t((1/(1+consistency['mean_diff']))*0.3 +\n",
    "\t\t (1/(1+consistency['avg_model_diff']))*0.3 +\n",
    "\t\t consistency['correlation']*0.4) * weights['consistency'] +\n",
    "\t\t(representativeness['avg_correlation']*0.5 +\n",
    "\t\t (1/(1+representativeness['avg_mean_diff']))*0.3 +\n",
    "\t\t (1/(1+representativeness['avg_std_diff']))*0.2) * weights['representativeness']\n",
    "\t)\n",
    "\n",
    "weights = {'consistency': 0.5, 'representativeness': 0.5}\n",
    "\n",
    "per_seed_rows = []\n",
    "detail_per_seed = []\n",
    "\n",
    "for seed in seeds:\n",
    "\tnp.random.seed(seed)\n",
    "\n",
    "\t# 调用前抑制内部print输出，避免重复日志冲刷\n",
    "\twith contextlib.redirect_stdout(io.StringIO()):\n",
    "\t\t# 方法一：难度分位桶法\n",
    "\t\tsubset1_bucket, subset2_bucket, _ = create_difficulty_bucket_subsets(\n",
    "\t\t\titem_acc_valid, valid_indices, SUBSET_SIZE, random_state=seed\n",
    "\t\t)\n",
    "\t\t# 方法二：IRT聚类法\n",
    "\t\tsubset1_irt, subset2_irt, _, _ = create_irt_clustering_subsets(\n",
    "\t\t\tvalid_indices, SUBSET_SIZE, random_state=seed\n",
    "\t\t)\n",
    "\t\t# 方法三：正误矩阵聚类法\n",
    "\t\tsubset1_matrix, subset2_matrix, _, _ = create_response_matrix_clustering_subsets(\n",
    "\t\t\tY_train, valid_indices, SUBSET_SIZE, random_state=seed\n",
    "\t\t)\n",
    "\n",
    "\tall_subsets_seed = {\n",
    "\t\t'subset1_bucket': subset1_bucket, 'subset2_bucket': subset2_bucket,\n",
    "\t\t'subset1_irt': subset1_irt, 'subset2_irt': subset2_irt,\n",
    "\t\t'subset1_matrix': subset1_matrix, 'subset2_matrix': subset2_matrix\n",
    "\t}\n",
    "\n",
    "\t# 各子集准确率（对所有395个模型）\n",
    "\tsubset_acc = {name: (Y[:, idxs].mean(axis=1)) for name, idxs in all_subsets_seed.items()}\n",
    "\n",
    "\t# 方法内部一致性（两个子集之间）\n",
    "\tmethod_consistency = {}\n",
    "\tfor method in ['bucket', 'irt', 'matrix']:\n",
    "\t\ta1 = subset_acc[f'subset1_{method}']\n",
    "\t\ta2 = subset_acc[f'subset2_{method}']\n",
    "\t\tdiffs = np.abs(a1 - a2)\n",
    "\t\tmethod_consistency[method] = {\n",
    "\t\t\t'mean_diff': float(abs(a1.mean() - a2.mean())),\n",
    "\t\t\t'std_diff': float(abs(a1.std() - a2.std())),\n",
    "\t\t\t'correlation': float(np.corrcoef(a1, a2)[0, 1]),\n",
    "\t\t\t'avg_model_diff': float(diffs.mean()),\n",
    "\t\t\t'max_model_diff': float(diffs.max())\n",
    "\t\t}\n",
    "\n",
    "\t# 代表性（相对完整MMLU）\n",
    "\tmethod_representativeness = {}\n",
    "\tfor method in ['bucket', 'irt', 'matrix']:\n",
    "\t\ta1 = subset_acc[f'subset1_{method}']\n",
    "\t\ta2 = subset_acc[f'subset2_{method}']\n",
    "\t\tcorr1 = float(np.corrcoef(a1, full_mmlu_acc)[0, 1])\n",
    "\t\tcorr2 = float(np.corrcoef(a2, full_mmlu_acc)[0, 1])\n",
    "\t\tdiff1 = float(abs(a1.mean() - full_mmlu_acc.mean()))\n",
    "\t\tdiff2 = float(abs(a2.mean() - full_mmlu_acc.mean()))\n",
    "\t\tstd1 = float(abs(a1.std() - full_mmlu_acc.std()))\n",
    "\t\tstd2 = float(abs(a2.std() - full_mmlu_acc.std()))\n",
    "\t\tmethod_representativeness[method] = {\n",
    "\t\t\t'avg_correlation': (corr1 + corr2) / 2,\n",
    "\t\t\t'avg_mean_diff': (diff1 + diff2) / 2,\n",
    "\t\t\t'avg_std_diff': (std1 + std2) / 2\n",
    "\t\t}\n",
    "\n",
    "\t# 评分与排序\n",
    "\tmethod_scores = {}\n",
    "\tfor method in ['bucket', 'irt', 'matrix']:\n",
    "\t\tmethod_scores[method] = float(compute_method_total_score(\n",
    "\t\t\tmethod_consistency[method],\n",
    "\t\t\tmethod_representativeness[method],\n",
    "\t\t\tweights\n",
    "\t\t))\n",
    "\n",
    "\tranking = sorted(method_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "\tbest_method = ranking[0][0]\n",
    "\n",
    "\t# 逐种子指标行（便于汇总/可视化）\n",
    "\tfor method in ['bucket', 'irt', 'matrix']:\n",
    "\t\tper_seed_rows.append({\n",
    "\t\t\t'seed': seed,\n",
    "\t\t\t'方法': method.upper(),\n",
    "\t\t\t'总分': method_scores[method],\n",
    "\t\t\t'与Full相关(均值)': method_representativeness[method]['avg_correlation'],\n",
    "\t\t\t'与Full均值差(均值)': method_representativeness[method]['avg_mean_diff'],\n",
    "\t\t\t'两子集相关': method_consistency[method]['correlation'],\n",
    "\t\t\t'两子集均值差': method_consistency[method]['mean_diff'],\n",
    "\t\t\t'两子集模型差(均值)': method_consistency[method]['avg_model_diff'],\n",
    "\t\t\t'排名': 1 + [m for m, _ in ranking].index(method)\n",
    "\t\t})\n",
    "\n",
    "\t# 保存详细结构化结果\n",
    "\tdetail_per_seed.append({\n",
    "\t\t'seed': seed,\n",
    "\t\t'ranking': ranking,\n",
    "\t\t'best_method': best_method,\n",
    "\t\t'method_scores': method_scores,\n",
    "\t\t'method_consistency': method_consistency,\n",
    "\t\t'method_representativeness': method_representativeness\n",
    "\t})\n",
    "\n",
    "# 聚合统计（方法层面）\n",
    "per_seed_df = pd.DataFrame(per_seed_rows)\n",
    "\n",
    "agg_rows = []\n",
    "for method in ['bucket', 'irt', 'matrix']:\n",
    "\t# dfm: data frame\n",
    "\tdfm = per_seed_df[per_seed_df['方法'] == method.upper()]\n",
    "\twins = int((dfm['排名'] == 1).sum())\n",
    "\tagg_rows.append({\n",
    "\t\t'方法': method.upper(),\n",
    "\t\t'胜出次数/10': wins,\n",
    "\t\t'平均排名': float(dfm['排名'].mean()),\n",
    "\t\t'总分(均值)': float(dfm['总分'].mean()),\n",
    "\t\t'总分(Std)': float(dfm['总分'].std()),\n",
    "\t\t'与Full相关(均值)': float(dfm['与Full相关(均值)'].mean()),\n",
    "\t\t'与Full相关(Std)': float(dfm['与Full相关(均值)'].std()),\n",
    "\t\t'与Full均值差(均值)': float(dfm['与Full均值差(均值)'].mean()),\n",
    "\t\t'与Full均值差(Std)': float(dfm['与Full均值差(均值)'].std()),\n",
    "\t\t'两子集相关(均值)': float(dfm['两子集相关'].mean()),\n",
    "\t\t'两子集相关(Std)': float(dfm['两子集相关'].std()),\n",
    "\t\t'两子集均值差(均值)': float(dfm['两子集均值差'].mean()),\n",
    "\t\t'两子集均值差(Std)': float(dfm['两子集均值差'].std()),\n",
    "\t\t'两子集模型差(均值)': float(dfm['两子集模型差(均值)'].mean()),\n",
    "\t\t'两子集模型差(Std)': float(dfm['两子集模型差(均值)'].std())\n",
    "\t})\n",
    "agg_df = pd.DataFrame(agg_rows).sort_values(['胜出次数/10', '总分(均值)'], ascending=[False, False])\n",
    "\n",
    "# 打印精简汇总\n",
    "print('=== 10个random_state 聚合结果（方法层面） ===')\n",
    "print(agg_df.to_string(index=False))\n",
    "\n",
    "print('\\n=== 每个random_state的最佳方法 ===')\n",
    "best_per_seed = pd.DataFrame([{'seed': d['seed'], 'best': d['best_method'].upper()} for d in detail_per_seed])\n",
    "print(best_per_seed.value_counts('best').to_string())\n",
    "\n",
    "# 保存结果到 subset_analysis_charts/\n",
    "os.makedirs('subset_analysis_charts', exist_ok=True)\n",
    "per_seed_df.to_csv('subset_analysis_charts/multi_seed_per_seed_metrics.csv', index=False, encoding='utf-8')\n",
    "agg_df.to_csv('subset_analysis_charts/multi_seed_aggregate_metrics.csv', index=False, encoding='utf-8')\n",
    "\n",
    "summary_payload = {\n",
    "\t'seeds': seeds,\n",
    "\t'aggregate': agg_df.to_dict('records'),\n",
    "\t'per_seed': per_seed_df.to_dict('records'),\n",
    "\t'detail_per_seed': detail_per_seed\n",
    "}\n",
    "with open('subset_analysis_charts/mmlu_ZH-CN_subset_summary.json', 'w', encoding='utf-8') as f:\n",
    "\tjson.dump(summary_payload, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print('\\n文件已保存：')\n",
    "print('- subset_analysis_charts/multi_seed_per_seed_metrics.csv')\n",
    "print('- subset_analysis_charts/multi_seed_aggregate_metrics.csv')\n",
    "print('- subset_analysis_charts/mmlu_ZH-CN_subset_summary.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d0903398",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\19119\\AppData\\Local\\Temp\\ipykernel_18232\\1470293344.py:43: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  sns.barplot(x='方法', y='胜出次数/10', data=plot_df, ax=ax, palette='Set2')\n",
      "C:\\Users\\19119\\AppData\\Local\\Temp\\ipykernel_18232\\1470293344.py:58: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  rank_stats = per_seed_df.groupby('方法')['排名'].agg(['mean','std']).reindex(method_order)\n",
      "C:\\Users\\19119\\AppData\\Local\\Temp\\ipykernel_18232\\1470293344.py:78: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  sns.boxplot(x='方法', y='总分', data=per_seed_df, ax=ax, palette='Set3')\n",
      "C:\\Users\\19119\\AppData\\Local\\Temp\\ipykernel_18232\\1470293344.py:134: FutureWarning: The default value of observed=False is deprecated and will change to observed=True in a future version of pandas. Specify observed=False to silence this warning and retain the current behavior\n",
      "  rank_pivot = per_seed_df.pivot_table(index='seed', columns='方法', values='排名')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "图表已生成到文件夹：subset_analysis_charts/\n",
      "\n",
      "文件列表：\n",
      "- aggregate_negative_metrics.png\n",
      "- aggregate_positive_metrics.png\n",
      "- avg_rank_with_std.png\n",
      "- consistency_scatter.png\n",
      "- mmlu_ZH-CN_subset_summary.json\n",
      "- multi_seed_aggregate_metrics.csv\n",
      "- multi_seed_per_seed_metrics.csv\n",
      "- per_seed_rank_heatmap.png\n",
      "- representativeness_scatter.png\n",
      "- total_score_box.png\n",
      "- wins_per_method.png\n"
     ]
    }
   ],
   "source": [
    "# 基于多随机种子结果，生成可视化图表到 subset_analysis_charts/\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 可选使用 seaborn，美化图表；若未安装则自动降级为纯 matplotlib\n",
    "try:\n",
    "\timport seaborn as sns\n",
    "\tHAS_SNS = True\n",
    "except Exception:\n",
    "\tHAS_SNS = False\n",
    "\n",
    "# 字体配置（Windows优先雅黑）\n",
    "plt.rcParams['font.sans-serif'] = ['Microsoft YaHei', 'SimHei', 'Arial Unicode MS', 'DejaVu Sans']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "in_per_seed = 'subset_analysis_charts/multi_seed_per_seed_metrics.csv'\n",
    "in_agg = 'subset_analysis_charts/multi_seed_aggregate_metrics.csv'\n",
    "in_summary = 'subset_analysis_charts/mmlu_ZH-CN_subset_summary.json'\n",
    "out_dir = 'subset_analysis_charts'\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "per_seed_df = pd.read_csv(in_per_seed)\n",
    "agg_df = pd.read_csv(in_agg)\n",
    "summary = None\n",
    "if os.path.exists(in_summary):\n",
    "\twith open(in_summary, 'r', encoding='utf-8') as f:\n",
    "\t\tsummary = json.load(f)\n",
    "\n",
    "# 统一方法顺序\n",
    "method_order = ['BUCKET', 'MATRIX', 'IRT']\n",
    "per_seed_df['方法'] = pd.Categorical(per_seed_df['方法'], categories=method_order, ordered=True)\n",
    "agg_df['方法'] = pd.Categorical(agg_df['方法'], categories=method_order, ordered=True)\n",
    "\n",
    "# 1) 各方法“胜出次数/10”条形图\n",
    "fig, ax = plt.subplots(figsize=(6,4), dpi=150)\n",
    "plot_df = agg_df.sort_values('方法')\n",
    "x = np.arange(len(plot_df))\n",
    "vals = plot_df['胜出次数/10'].values\n",
    "if HAS_SNS:\n",
    "\tsns.barplot(x='方法', y='胜出次数/10', data=plot_df, ax=ax, palette='Set2')\n",
    "else:\n",
    "\tax.bar(x, vals, color=['#66c2a5','#8da0cb','#fc8d62'])\n",
    "\tax.set_xticks(x)\n",
    "\tax.set_xticklabels(plot_df['方法'])\n",
    "ax.set_title('各方法胜出次数（10个random_state）')\n",
    "ax.set_xlabel('方法')\n",
    "ax.set_ylabel('胜出次数/10')\n",
    "for i, v in enumerate(vals):\n",
    "\tax.text(i, v + 0.1, str(int(v)), ha='center', va='bottom', fontsize=9)\n",
    "plt.tight_layout()\n",
    "fig.savefig(os.path.join(out_dir, 'wins_per_method.png'))\n",
    "plt.close(fig)\n",
    "\n",
    "# 2) 平均排名（含标准差误差棒）\n",
    "rank_stats = per_seed_df.groupby('方法')['排名'].agg(['mean','std']).reindex(method_order)\n",
    "fig, ax = plt.subplots(figsize=(6,4), dpi=150)\n",
    "if HAS_SNS:\n",
    "\tax.errorbar(rank_stats.index, rank_stats['mean'], yerr=rank_stats['std'], fmt='o-', capsize=4)\n",
    "else:\n",
    "\tax.errorbar(np.arange(len(rank_stats)), rank_stats['mean'], yerr=rank_stats['std'], fmt='o-', capsize=4)\n",
    "\tax.set_xticks(np.arange(len(rank_stats)))\n",
    "\tax.set_xticklabels(rank_stats.index)\n",
    "ax.set_title('平均排名（误差棒为标准差）')\n",
    "ax.set_xlabel('方法')\n",
    "ax.set_ylabel('排名（越小越好）')\n",
    "for i, (m, row) in enumerate(rank_stats.iterrows()):\n",
    "\tax.text(i, row['mean'], f\"{row['mean']:.2f}\", ha='center', va='bottom', fontsize=9)\n",
    "plt.tight_layout()\n",
    "fig.savefig(os.path.join(out_dir, 'avg_rank_with_std.png'))\n",
    "plt.close(fig)\n",
    "\n",
    "# 3) 各方法总分分布（箱线图）\n",
    "fig, ax = plt.subplots(figsize=(6,4), dpi=150)\n",
    "if HAS_SNS:\n",
    "\tsns.boxplot(x='方法', y='总分', data=per_seed_df, ax=ax, palette='Set3')\n",
    "\tsns.stripplot(x='方法', y='总分', data=per_seed_df, ax=ax, color='k', alpha=0.5, size=4, jitter=True)\n",
    "else:\n",
    "\t# 手动箱线图\n",
    "\tdata_list = [per_seed_df[per_seed_df['方法']==m]['总分'].values for m in method_order]\n",
    "\tax.boxplot(data_list, labels=method_order, patch_artist=True,\n",
    "\t           boxprops=dict(facecolor='#d9d9d9'))\n",
    "\tax.scatter(per_seed_df['方法'].cat.codes+1, per_seed_df['总分'], s=10, c='k', alpha=0.6)\n",
    "ax.set_title('各方法总分分布（10个random_state）')\n",
    "ax.set_xlabel('方法')\n",
    "ax.set_ylabel('总分（越高越好）')\n",
    "plt.tight_layout()\n",
    "fig.savefig(os.path.join(out_dir, 'total_score_box.png'))\n",
    "plt.close(fig)\n",
    "\n",
    "# 4) 代表性：与完整MMLU相关 vs 与完整MMLU均值差 散点图（按方法着色）\n",
    "fig, ax = plt.subplots(figsize=(6,4), dpi=150)\n",
    "if HAS_SNS:\n",
    "\tsns.scatterplot(\n",
    "\t\tdata=per_seed_df, x='与Full均值差(均值)', y='与Full相关(均值)',\n",
    "\t\thue='方法', hue_order=method_order, style='方法', ax=ax, s=60, palette='Set2'\n",
    "\t)\n",
    "else:\n",
    "\tcolors = {'BUCKET':'#66c2a5', 'MATRIX':'#8da0cb', 'IRT':'#fc8d62'}\n",
    "\tfor m in method_order:\n",
    "\t\tdfm = per_seed_df[per_seed_df['方法']==m]\n",
    "\t\tax.scatter(dfm['与Full均值差(均值)'], dfm['与Full相关(均值)'], s=60, c=colors[m], label=m)\n",
    "ax.set_title('代表性：与完整MMLU相关 vs 均值差')\n",
    "ax.set_xlabel('与Full均值差（越小越好）')\n",
    "ax.set_ylabel('与Full相关（越大越好）')\n",
    "ax.legend(title='方法')\n",
    "plt.tight_layout()\n",
    "fig.savefig(os.path.join(out_dir, 'representativeness_scatter.png'))\n",
    "plt.close(fig)\n",
    "\n",
    "# 5) 一致性：两子集相关 vs 两子集模型差(均值) 散点图（按方法着色）\n",
    "fig, ax = plt.subplots(figsize=(6,4), dpi=150)\n",
    "if HAS_SNS:\n",
    "\tsns.scatterplot(\n",
    "\t\tdata=per_seed_df, x='两子集模型差(均值)', y='两子集相关',\n",
    "\t\thue='方法', hue_order=method_order, style='方法', ax=ax, s=60, palette='Set1'\n",
    "\t)\n",
    "else:\n",
    "\tcolors = {'BUCKET':'#e41a1c', 'MATRIX':'#377eb8', 'IRT':'#4daf4a'}\n",
    "\tfor m in method_order:\n",
    "\t\tdfm = per_seed_df[per_seed_df['方法']==m]\n",
    "\t\tax.scatter(dfm['两子集模型差(均值)'], dfm['两子集相关'], s=60, c=colors[m], label=m)\n",
    "ax.set_title('一致性：两子集相关 vs 模型差(均值)')\n",
    "ax.set_xlabel('两子集模型差(均值)（越小越好）')\n",
    "ax.set_ylabel('两子集相关（越大越好）')\n",
    "ax.legend(title='方法')\n",
    "plt.tight_layout()\n",
    "fig.savefig(os.path.join(out_dir, 'consistency_scatter.png'))\n",
    "plt.close(fig)\n",
    "\n",
    "# 6) 每个random_state的排名热力图（行：seed，列：方法）\n",
    "rank_pivot = per_seed_df.pivot_table(index='seed', columns='方法', values='排名')\n",
    "fig, ax = plt.subplots(figsize=(6, max(3, 0.4*len(rank_pivot))), dpi=150)\n",
    "if HAS_SNS:\n",
    "\tsns.heatmap(rank_pivot.loc[sorted(rank_pivot.index)], annot=True, fmt='.0f',\n",
    "\t            cmap='YlGnBu', cbar=True, ax=ax)\n",
    "else:\n",
    "\t# 简化版：使用imshow\n",
    "\tim = ax.imshow(rank_pivot.loc[sorted(rank_pivot.index)].values, cmap='YlGnBu', aspect='auto')\n",
    "\tax.set_xticks(np.arange(len(rank_pivot.columns)))\n",
    "\tax.set_xticklabels(rank_pivot.columns)\n",
    "\tax.set_yticks(np.arange(len(rank_pivot.index)))\n",
    "\tax.set_yticklabels(sorted(rank_pivot.index))\n",
    "\tfor i in range(len(rank_pivot.index)):\n",
    "\t\tfor j in range(len(rank_pivot.columns)):\n",
    "\t\t\tval = rank_pivot.loc[sorted(rank_pivot.index)[i], rank_pivot.columns[j]]\n",
    "\t\t\tax.text(j, i, f'{int(val)}', ha='center', va='center', color='black', fontsize=8)\n",
    "\tfig.colorbar(im, ax=ax, fraction=0.046, pad=0.04)\n",
    "ax.set_title('每个random_state的排名（数值越小越好）')\n",
    "plt.tight_layout()\n",
    "fig.savefig(os.path.join(out_dir, 'per_seed_rank_heatmap.png'))\n",
    "plt.close(fig)\n",
    "\n",
    "# 7) 汇总柱状图：各方法的关键指标均值（来自聚合表）\n",
    "# 使用聚合表中的关键列：'总分(均值)'、'与Full相关(均值)'、'与Full均值差(均值)'、'两子集相关(均值)'、'两子集均值差(均值)'、'两子集模型差(均值)'\n",
    "key_cols = ['总分(均值)', '与Full相关(均值)', '与Full均值差(均值)', '两子集相关(均值)', '两子集均值差(均值)', '两子集模型差(均值)']\n",
    "agg_plot = agg_df.set_index('方法').loc[method_order, key_cols]\n",
    "\n",
    "# 分两张图显示：正向指标与反向指标\n",
    "pos_cols = ['总分(均值)', '与Full相关(均值)', '两子集相关(均值)']\n",
    "neg_cols = ['与Full均值差(均值)', '两子集均值差(均值)', '两子集模型差(均值)']\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(7,4), dpi=150)\n",
    "if HAS_SNS:\n",
    "\tagg_plot[pos_cols].plot(kind='bar', ax=ax, colormap='Set2')\n",
    "else:\n",
    "\tagg_plot[pos_cols].plot(kind='bar', ax=ax)\n",
    "ax.set_title('关键正向指标对比（越高越好）')\n",
    "ax.set_xlabel('方法')\n",
    "ax.set_ylabel('数值')\n",
    "plt.tight_layout()\n",
    "fig.savefig(os.path.join(out_dir, 'aggregate_positive_metrics.png'))\n",
    "plt.close(fig)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(7,4), dpi=150)\n",
    "if HAS_SNS:\n",
    "\tagg_plot[neg_cols].plot(kind='bar', ax=ax, colormap='Set3')\n",
    "else:\n",
    "\tagg_plot[neg_cols].plot(kind='bar', ax=ax)\n",
    "ax.set_title('关键反向指标对比（越低越好）')\n",
    "ax.set_xlabel('方法')\n",
    "ax.set_ylabel('数值')\n",
    "plt.tight_layout()\n",
    "fig.savefig(os.path.join(out_dir, 'aggregate_negative_metrics.png'))\n",
    "plt.close(fig)\n",
    "\n",
    "print('图表已生成到文件夹：subset_analysis_charts/')\n",
    "print('\\n文件列表：')\n",
    "for f in sorted(os.listdir(out_dir)):\n",
    "\tprint('-', f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccaa8efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf43608",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc3752ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TinyBenchEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
